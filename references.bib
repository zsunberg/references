@String { aaai        = {AAAI Conference on Artificial Intelligence (AAAI)} }
@String { aamas       = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)} }
@String { acc         = {American Control Conference (ACC)} }
@String { atm         = {Air Traffic Management Research and Development Seminar}}
@String { aiaa_info   = {AIAA Infotech@Aerospace Conference} }
@String { aiaa_jacic  = {Journal of Aerospace Computing, Information, and Communication} }
@String { allerton    = {Allerton Conference on Communication, Control, and Compution} }
@String { atio        = {AIAA Aviation Technology, Integration, and Operations Conference (ATIO)} }
@String { cacm        = {Communications of the ACM} }
@String { cav         = {International Conference on Computer-Aided Verification} }
@String { cdc         = {IEEE Conference on Decision and Control (CDC)} }
@String { cvpr        = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)} }
@String { dasc        = {Digital Avionics Systems Conference (DASC)} }
@String { ecml        = {European Conference on Machine Learning (ECML)} }
@String { gnc         = {AIAA Guidance, Navigation, and Control Conference (GNC)} }
@String { icaart      = {International Conference on Agents and Artificial Intelligence (ICAART)} }
@String { icaps       = {International Conference on Automated Planning and Scheduling (ICAPS)} }
@String { icassp      = {International Conference on Acoustics, Speech, and Signal Processing (ICASSP)} }
@String { iclr        = {International Conference on Learning Representations (ICLR)} }
@String { icml        = {International Conference on Machine Learning (ICML)} }
@String { icmla       = {International Conference on Machine Learning and Applications (ICMLA)} }
@String { icra        = {IEEE International Conference on Robotics and Automation (ICRA)} }
@String { icslp       = {International Conference on Spoken Language Processing (ICSLP)} }
@String { ieee_csm    = {IEEE Control Systems Magazine} }
@String { ieee_tc     = {IEEE Transactions on Cybernetics} }
@String { ieee_j_ac   = {IEEE Transactions on Automatic Control} }
@String { ieeeaero    = {IEEE Aerospace Conference} }
@String { ieeeciaig   = {IEEE Transactions on Computational Intelligence and AI in Games} }
@String { ieeecst     = {IEEE Transactions on Control Systems Technology} }
@String { ieeetiv     = {IEEE Transactions on Intelligent Vehicles} }
@String { ieeetac     = {IEEE Transactions on Automatic Control} }
@String { ieeetits     = {IEEE Transactions on Intelligent Transportation Systems} }
@String { ieeetsp     = {IEEE Transactions on Signal Processing} }
@String { ijcai       = {International Joint Conference on Artificial Intelligence (IJCAI)} }
@String { ijrr        = {International Journal of Robotics Research} }
@String { interspeech = {Annual Conference of the International Speech Communication Association (INTERSPEECH)} }
@String { iros        = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)} }
@String { itsc        = {IEEE International Conference on Intelligent Transportation Systems (ITSC)} }
@String { iv          = {IEEE Intelligent Vehicles Symposium (IV)} }
@String { jaamas      = {Journal of Autonomous Agents and Multi-Agent Systems} }
@String { jair        = {Journal of Artificial Intelligence Research} }
@String { jgcd        = {AIAA Journal of Guidance, Control, and Dynamics} }
@String { jmlr        = {Journal of Machine Learning Research} }
@String { jota        = {Journal of Optimization Theory and Applications} }
@String { lion        = {Learning and Intelligent Optimization (LION)} }
@String { mor         = {Mathematics of Operations Research} }
@String { nips        = {Advances in Neural Information Processing Systems (NIPS)} }
@String { neurips     = {Advances in Neural Information Processing Systems (NeurIPS)} }
@String { or          = {Operations Research} }
@String { rss         = {Robotics: Science and Systems} }
@String { sigcomm     = {ACM Special Interest Group on Data Communication (SIGCOMM)} }
@String { tac         = {IEEE Transactions on Automatic Control} }
@String { tacas       = {International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS)} }
@String { taes        = {IEEE Transactions on Aerospace and Electronic Systems} }
@String { uai         = {Conference on Uncertainty in Artificial Intelligence (UAI)} }
@String { hri         = {ACM/IEEE International Conference on Human-Robot Interaction (HRI)} }

@inproceedings{sunberg2018pomcpow,
  title={Online Algorithms for {POMDP}s with Continuous State, Action, and Observation Spaces},
  author={Zachary Sunberg and Mykel J. Kochenderfer},
  author+an={1=me},
  booktitle={International Conference on Automated Planning and Scheduling},
  year={2018}
}

@inproceedings{garg2019despotalpha,
  title={{DESPOT}-$\alpha$: Online {POMDP} Planning With Large State And Observation Spaces},
  author={Neha P. Garg and David Hsu and Wee Sun Lee},
  booktitle={Robotics: Science and Systems},
  year={2019}
}

@inproceedings{lee2020monte,
  title={{M}onte-{C}arlo Tree Search in Continuous Action Spaces with Value Gradients},
  author={Lee, Jongmin and Jeon, Wonseok and Kim, Geon-Hyeong and Kim, Kee-Eung},
  booktitle=aaai,
  pages={4561--4568},
  year={2020}
}

@inproceedings{kim2020monte,
  title={Monte Carlo Tree Search in Continuous Spaces Using Voronoi Optimistic Optimization with Regret Bounds.},
  author={Kim, Beomjoon and Lee, Kyungjae and Lim, Sungbin and Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle=aaai,
  pages={9916--9924},
  year={2020}
}

@inproceedings{lim2020sparse,
  title={Sparse Tree Search Optimality Guarantees in {POMDP}s with Continuous Observation Spaces},
  author={Lim, Michael H. and Tomlin, Claire J. and Sunberg, Zachary N.},
  author+an={3=me},
  year={2020},
  booktitle=ijcai
}

@inproceedings{garg2019learning,
  title={Learning To Grasp Under Uncertainty Using POMDPs},
  author={Garg, Neha P and Hsu, David and Lee, Wee Sun},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={2751--2757},
  year={2019},
  organization={IEEE}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@misc{darpa2020ace,
    title={Broad Agency Announcement: Air Combat Evolution Technical Area 1: Build Combat Autonomy},
    author={Defence Advanced Research Projects Agency (DARPA)},
    year={2020}
}

@article {jaderberg2019quake,
	author = {Jaderberg, Max and Czarnecki, Wojciech M. and Dunning, Iain and Marris, Luke and Lever, Guy and Casta{\~n}eda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C. and Morcos, Ari S. and Ruderman, Avraham and Sonnerat, Nicolas and Green, Tim and Deason, Louise and Leibo, Joel Z. and Silver, David and Hassabis, Demis and Kavukcuoglu, Koray and Graepel, Thore},
	title = {Human-level performance in 3D multiplayer games with population-based reinforcement learning},
	volume = {364},
	number = {6443},
	pages = {859--865},
	year = {2019},
	doi = {10.1126/science.aau6249},
	publisher = {American Association for the Advancement of Science},
	abstract = {Artificially intelligent agents are getting better and better at two-player games, but most real-world endeavors require teamwork. Jaderberg et al. designed a computer program that excels at playing the video game Quake III Arena in Capture the Flag mode, where two multiplayer teams compete in capturing the flags of the opposing team. The agents were trained by playing thousands of games, gradually learning successful strategies not unlike those favored by their human counterparts. Computer agents competed successfully against humans even when their reaction times were slowed to match those of humans.Science, this issue p. 859Reinforcement learning (RL) has shown great success in increasingly complex single-agent environments and two-player turn-based games. However, the real world contains multiple agents, each learning and acting independently to cooperate and compete with other agents. We used a tournament-style evaluation to demonstrate that an agent can achieve human-level performance in a three-dimensional multiplayer first-person video game, Quake III Arena in Capture the Flag mode, using only pixels and game points scored as input. We used a two-tier optimization process in which a population of independent RL agents are trained concurrently from thousands of parallel matches on randomly generated environments. Each agent learns its own internal reward signal and rich representation of the world. These results indicate the great potential of multiagent reinforcement learning for artificial intelligence research.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/364/6443/859},
	eprint = {https://science.sciencemag.org/content/364/6443/859.full.pdf},
	journal = {Science}
}

@Article{kearns2002sparse,
    author="Kearns, Michael and Mansour, Yishay and Ng, Andrew Y.",
    title="A Sparse Sampling Algorithm for Near-Optimal Planning in Large {M}arkov Decision Processes",
    journal="Machine Learning",
    year="2002",
    month="Nov",
    day="01",
    volume="49",
    number="2",
    pages="193--208",
    issn="1573-0565",
}

@article {silver2018alphago,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters {C}hess, {S}hogi, and {G}o through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	doi = {10.1126/science.aar6404},
	publisher = {American Association for the Advancement of Science},
	abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.Science, this issue p. 1140; see also pp. 1087 and 1118The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/362/6419/1140},
	eprint = {https://science.sciencemag.org/content/362/6419/1140.full.pdf},
	journal = {Science}
}

@inproceedings{silver2010pomcp,
    title = {{M}onte-{C}arlo Planning in Large {POMDP}s},
    author = {Silver, David and Veness, Joel},
    booktitle = {Advances in Neural Information Processing Systems},
    pages = {2164--2172},
    year = {2010},
    url = {http://papers.nips.cc/paper/4031-monte-carlo-planning-in-large-pomdps.pdf}
}

@article{ye2017despot,
  title={{DESPOT}: Online {POMDP} Planning with Regularization},
  author={Ye, Nan and Somani, Adhiraj and Hsu, David and Lee, Wee Sun},
  journal={Journal of Artificial Intelligence Research},
  volume={58},
  pages={231--266},
  year={2017}
}

@inproceedings{seiler2015online,
  title={An online and approximate solver for {POMDP}s with continuous action space},
  author={Seiler, Konstantin M. and Kurniawati, Hanna and Singh, Surya P. N.},
  booktitle=icra,
  pages={2290--2297},
  year={2015},
}
% GPS-ABT

@article{browne2012survey,
  title={A survey of {M}onte {C}arlo tree search methods},
  author={Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  journal={{IEEE} Transactions on Computational Intelligence and {AI} in games},
  volume={4},
  number={1},
  pages={1--43},
  year={2012},
}

@inproceedings{keller2013trial,
  title={Trial-based heuristic tree search for finite horizon MDPs},
  author={Keller, Thomas and Helmert, Malte},
  booktitle={Twenty-Third International Conference on Automated Planning and Scheduling},
  year={2013}
}

@inproceedings{sunberg2017value,
    title={The Value of Inferring the Internal State of Traffic Participants for Autonomous Freeway Driving},
    author={Sunberg, Zachary N. and Ho, Christopher J. and Kochenderfer, Mykel, J.},
    author+an={1=me},
    booktitle=acc,
    year={2017}
}

@inproceedings{couetoux2011double,
  address = {Rome, Italy},
  annote = {double progressive widening},
  author = {Cou\"{e}toux, A. and Hoock, J.-B. and Sokolovska, N. and Teytaud, O. and Bonnard, N.},
  booktitle = {Learning and Intelligent Optimization},
  mendeley-groups = {UAVCAS,POMDPs,MDPs},
  title = {Continuous Upper Confidence Trees},
  year = {2011}
}

@inproceedings{frank2007hover,
  title={Hover, transition, and level flight control design for a single-propeller indoor airplane},
  author={Frank, Adrian and McGrew, James and Valenti, Mario and Levine, Daniel and How, Jonathan},
  booktitle={AIAA Guidance, Navigation and Control Conference and Exhibit},
  pages={6318},
  year={2007}
}

@book{shaw1985fighter,
  title={Fighter Combat: Tactics and Maneuvering},
  author={Shaw, Robert L.},
  year={1985},
  publisher={Naval Institute Press},
  address={Annapolis}
}

@Article{holland2013optimizing,
  Title                    = {Optimizing the Next Generation Collision Avoidance System for Safe, Suitable, and Acceptable Operational Performance},
  Author                   = {Jessica E. Holland and Mykel J. Kochenderfer and Wesley A. Olson},
  Journal                  = {{A}ir {T}raffic {C}ontrol {Q}uarterly},
  Year                     = {2013},
  Number                   = {3},
  Pages                    = {275-297},
  Volume                   = {21}
}

@inproceedings{cassandra1998survey,
  title={A survey of {POMDP} applications},
  author={Cassandra, Anthony R},
  booktitle={Working notes of {AAAI} 1998 fall symposium on planning with partially observable {M}arkov decision processes},
  year={1998}
}

@article{ayer2012mammography,
  title={A {POMDP} approach to personalize mammography screening decisions},
  author={Ayer, Turgay and Alagoz, Oguzhan and Stout, Natasha K},
  journal={Operations Research},
  volume={60},
  number={5},
  pages={1019--1034},
  year={2012},
  publisher={INFORMS}
}

@inproceedings{wang2018online,
  title={An Online Planner for {POMDP}s with Large Discrete Action Space: A Quantile-Based Approach.},
  author={Wang, Erli and Kurniawati, Hanna and Kroese, Dirk P.},
  booktitle=icaps,
  year={2018}
}

@article{papadimitriou1987complexity,
  title={The Complexity of {M}arkov Decision Processes},
  author={Papadimitriou, Christos H. and Tsitsiklis, John N.},
  journal={Mathematics of Operations Research},
  volume={12},
  number={3},
  pages={441--450},
  year={1987},
  publisher={{INFORMS}}
}

@inproceedings{littman1995learning,
  title={Learning Policies for Partially Observable Environments: Scaling Up},
  author={Littman, M. L. and Cassandra, A. R. and Kaelbling, L. P.},
  booktitle=icml,
  year={1995}
}

@inproceedings{kurniawati2008sarsop,
  title={{SARSOP}: Efficient Point-based {POMDP} Planning by Approximating Optimally Reachable Belief Spaces},
  author={Kurniawati, Hanna and Hsu, David and Lee, Wee Sun},
  booktitle=rss,
  volume={2008},
  year={2008},
}


@techreport{young2020architecture,
  title={Architecture and Information Requirements to Assess and Predict Flight Safety Risks During Highly Autonomous Urban Flight Operations},
  author={Young, Steven and Ancel, Ersin and Moore, Andrew and Dill, Evan and Quach, Cuong and Foster, John and Darafsheh, Kaveh and Smalling, Kyle and Vazquez, Sixto and Evans, Emory and others},
  year={2020},
  institution={NASA},
  number={TM-2020-220440}
}

@book{nas2018aviation,
    title={In-Time Aviation Safety Mangement: Challenges and Research for an Evolving Aviation System},
    author={{National Academies of Sciences, Engineering, and Medicine}},
    publisher={The National Academies Press},
    year={2018},
    doi={10.17226/24962}
}

@book{nasa2019strategic,
    title={{NASA} Aeronautics Strategic Implementation Plan},
    author={{National Aeronautics and Space Administration}},
    year={2019}
}

@inproceedings{bouton2018utility,
  title={Utility Decomposition with Deep Corrections for Scalable Planning under Uncertainty},
  author={Bouton, Maxime and Julian, Kyle and Nakhaei, Alireza and Fujimura, Kikuo and Kochenderfer, Mykel J.},
  booktitle=aamas,
  pages={462--469},
  year={2018}
}

@inproceedings{bouton2020point,
  title={Point-Based Methods for Model Checking in Partially Observable Markov Decision Processes},
  author={Bouton, Maxime and Tumova, Jana and Kochenderfer, Mykel J.},
  booktitle=aaai,
  pages={10061--10068},
  year={2020}
}

@inproceedings{lee2015adaptive,
  title={Adaptive Stress Testing of Airborne Collision Avoidance Systems},
  author={Lee, Ritchie and Kochenderfer, Mykel J. and Mengshoel, Ole J. and Brat, Guillaume P. and Owen, Michael P.},
  booktitle=dasc,
  year={2015},
  organization={{IEEE}}
}

@article{best2019dec,
  title={Dec-{MCTS}: Decentralized Planning for Multi-Robot Active Perception},
  author={Best, Graeme and Cliff, Oliver M. and Patten, Timothy and Mettu, Ramgopal R. and Fitch, Robert},
  journal=ijrr,
  volume={38},
  number={2-3},
  pages={316--337},
  year={2019},
  publisher={SAGE Publications}
}

@techreport{knkt2018accident,
    author={{Komite Nasional Keselamatan Transportasi}},
    title={Aircraft Accident Investigation Report},
    year={2018},
    number={KNKT.18.10.35.04}
}

@unpublished{sunberg2021improving,
    author={Sunberg, Zachary and Kochenderfer, Mykel},
    author+an={1=me},
    title={Improving Automated Driving through Planning with Human Internal States},
    note={Under revision for {IEEE} Transactions on Intelligent Transportation Systems},
    url={https://arxiv.org/abs/2005.14549}
}

@article{egorov2017pomdps,
  author  = {Maxim Egorov and Zachary N. Sunberg and Edward Balaban and Tim A. Wheeler and Jayesh K. Gupta and Mykel J. Kochenderfer},
  title   = {{POMDP}s.jl: A Framework for Sequential Decision Making under Uncertainty},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  volume  = {18},
  number  = {26},
  pages   = {1-5},
  url     = {http://jmlr.org/papers/v18/16-300.html}
}

@inproceedings{sunberg2016trusted,
    title={Optimized and Trusted Collision Avoidance for Unmanned Aerial Vehicles using Approximate Dynamic Programming},
    author={Sunberg, Zachary and Kochenderfer, Mykel J. and Pavone, Marco},
    author+an={1=me},
    booktitle=icra,
    address={Stockholm},
    url={https://arxiv.org/abs/1602.04762},
    url_Paper={https://arxiv.org/pdf/1602.04762.pdf},
    year={2016}
}

@article{sunberg2015real,
    title = "A Real-Time Expert Control System For Helicopter Autorotation",
    author = {Sunberg, Zachary N. and Miller, Nathaniel R. and Rogers, Jonathan D.},
    author+an={1=me},
    journal = "Journal of the American Helicopter Society",
    parent_itemid = "infobike://ahs/jahs",
    publishercode ="ahs",
    year = "2015",
    volume = "60",
    number = "2",
    pages = "1-15",
    itemtype = "ARTICLE",
    issn = "2161-6027",
    url = "http://www.ingentaconnect.com/content/ahs/jahs/2015/00000060/00000002/art00008",
    url_Paper = "http://www.ingentaconnect.com/content/ahs/jahs/2015/00000060/00000002/art00008",
    doi = "10.4050/JAHS.60.022008"
}

@inproceedings{peters2020alignment,
    author={Lasse Peters and David Fridovich-Keil and Claire Tomlin and Zachary Sunberg},
    author+an={4=me},
    title={Inference-Based Strategy Alignment for General-Sum Differential Games},
    booktitle=aamas,
    year=2020,
    url={https://github.com/lassepe/AAMAS2020-GameInference-Paper/blob/master/submission/ibsa-camera-ready-aamas2020.pdf},
    url_Paper={https://github.com/lassepe/AAMAS2020-GameInference-Paper/blob/master/submission/ibsa-camera-ready-aamas2020.pdf}
}

@article{slade2020estimation,
    author={Patrick Slade and Zachary Sunberg and Mykel J. Kochenderfer},
    author+an={2=me},
    title={Estimation and Control Using Sampling-Based {B}ayesian Reinforcement Learning},
    journal={{IET} Cyber-Physical Systems: Theory and Applications},
    year={2020},
    volume={5},
    issue={1},
    url={https://digital-library.theiet.org/content/journals/10.1049/iet-cps.2019.0045}
}

@inproceedings{sonu2018hierarchy,
    title={Exploiting Hierarchy for Scalable Decision Making in Autonomous Driving},
    author={Sonu, Ekhlas and Sunberg, Zachary and Kochenderfer, Mykel J.},
    author+an={2=me},
    booktitle={Intelligent Vehicles Symposium},
    year={2018},
    address={Changshu}
}

@article{sunberg2016information,
    title={Information Space Receding Horizon Control for Multisensor Tasking Problems},
    author={Sunberg, Zachary and Chakravorty, Suman and Erwin, Richard Scott},
    author+an={1=me},
    journal=ieee_tc,
    volume={46},
    number={6},
    pages={1325--1336},
    year={2016},
    url={http://ieeexplore.ieee.org/document/7174988/},
    url_Paper={http://ieeexplore.ieee.org/document/7174988/},
}

@article{sunberg2013belief,
    title = "A Belief Function Distance Metric for Orderable Sets",
    journal = "Information Fusion",
    volume = "14",
    number = "4",
    pages = "361--373",
    year = "2013",
    issn = "1566-2535",
    doi = "10.1016/J.INFFUS.2013.03.003",
    url = "http://www.sciencedirect.com/science/article/pii/S1566253513000304",
    author = "Zachary Sunberg and Jonathan Rogers",
    author+an={2=me},
    keywords = "Dempster–Shafer theory",
    keywords = "Distance metric",
    keywords = "Orderable sets",
    keywords = "Sensor fault detection"
}

@Book{kochenderfer2015decision,
  title =         {Decision Making Under Uncertainty: Theory and Application},
  publisher =     {{MIT} Press},
  year =          {2015},
  author =        {Mykel J. Kochenderfer}
}

@article{ross2008online,
  title={Online planning algorithms for {POMDP}s},
  author={Ross, St{\'e}phane and Pineau, Joelle and Paquet, S{\'e}bastien and Chaib-Draa, Brahim},
  journal={Journal of Artificial Intelligence Research},
  volume={32},
  pages={663--704},
  year={2008}
}

@report{bea2012airfrance,
  title={Final report on the accident on 1st June 2009 to the Airbus A330-203 registered F-GZCP operated by Air France flight AF 447 Rio de Janeiro--Paris},
  author={Bureau d’Enqu{\^e}tes et d’Analyses},
  year={2012}
}

@inproceedings{moore2018testing,
  title={Testing enabling technologies for safe {UAS} urban operations},
  author={Moore, Andrew and Balachandran, Swee and Young, Steven D and Dill, Evan T and Logan, Michael J and Glaab, Louis J and Munoz, Cesar and Consiglio, Maria},
  booktitle={2018 Aviation Technology, Integration, and Operations Conference},
  pages={3200},
  year={2018}
}

@inproceedings{consiglio2016icarous,
  title={{ICAROUS}: Integrated configurable algorithms for reliable operations of unmanned systems},
  author={Consiglio, Mar{\'\i}a and Munoz, C{\'e}sar and Hagen, George and Narkawicz, Anthony and Balachandran, Swee},
  booktitle=dasc,
  year={2016}
}

@book{bertsekas1995dynamic,
  title={Dynamic Programming and Optimal Control},
  author={Bertsekas, Dimitri P.},
  year={1995},
  publisher={Athena Scientific}
}

@book{koller2009probabilistic,
  title={Probabilistic Graphical Models: Principles and Techniques},
  author={Koller, Daphne and Friedman, Nir},
  year={2009},
  publisher={MIT press}
}

@article{ferreiro2012application,
  title={Application of {B}ayesian Networks in Prognostics for a New Integrated Vehicle Health Management Concept},
  author={Ferreiro, Susana and Arnaiz, Aitor and Sierra, Basilio and Irigoien, Itziar},
  journal={Expert Systems with Applications},
  volume={39},
  number={7},
  pages={6402--6418},
  year={2012},
  publisher={Elsevier}
}

@article{xu2015data,
  title={Data mining--based intelligent fault diagnostics for integrated system health management to avionics},
  author={Xu, Jiuping and Sun, Kai and Xu, Lei},
  journal={Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
  volume={229},
  number={1},
  pages={3--15},
  year={2015},
  publisher={{SAGE} Publications Sage UK: London, England}
}

@inproceedings{fridovich2020efficient,
  title={Efficient Iterative Linear-quadratic Approximations for Nonlinear Multi-player General-sum Differential Games},
  author={Fridovich-Keil, David and Ratner, Ellis and Peters, Lasse and Dragan, Anca D and Tomlin, Claire J},
  booktitle=icra,
  pages={1475--1481},
  year={2020},
  organization={IEEE}
}

@inproceedings{mern2021bayesian,
  title={Bayesian Optimized {M}onte {C}arlo Planning}, 
  author={John Mern and Anil Yildiz and Zachary Sunberg and Tapan Mukerji and Mykel J. Kochenderfer},
  author+an={3=me},
  year={2021},
  booktitle=aaai
}

@misc{hoerger2020online,
      title={An On-Line POMDP Solver for Continuous Observation Spaces}, 
      author={Marcus Hoerger and Hanna Kurniawati},
      year={2020},
      eprint={2011.02076},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

%%article{vinyals2019grandmaster,
%  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
%  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
%  journal={Nature},
%  volume={575},
%  number={7782},
%  pages={350--354},
%  year={2019},
%  publisher={Nature Publishing Group}
%}

@article{vinyals2019grandmaster,
author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M.  and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H.  and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P.  and Jaderberg, Max and Vezhnevets, Alexander S.  and Leblond, R{\'e}mi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L.  and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and W{\"u}nsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
journal={Nature},
year={2019},
month={Nov},
day={01},
volume={575},
number={7782},
pages={350-354},
abstract={Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1--3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8{\%} of officially ranked human players.},
issn={1476-4687},
doi={10.1038/s41586-019-1724-z},
url={https://doi.org/10.1038/s41586-019-1724-z}
}

@misc{darpa2020alpha,
    title={{A}lpha{D}ogfight Trials Foreshadow Future of Human-Machine Symbiosis},
    url={https://www.darpa.mil/news-events/2020-08-26}
}

@article{openai2019dota,
  title={Dota 2 with Large Scale Deep Reinforcement Learning},
  author={OpenAI and Christopher Berner and Greg Brockman and Brooke Chan and Vicki Cheung and Przemysław Dębiak and Christy Dennison and David Farhi and Quirin Fischer and Shariq Hashme and Chris Hesse and Rafal Józefowicz and Scott Gray and Catherine Olsson and Jakub Pachocki and Michael Petrov and Henrique Pondé de Oliveira Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang},
  year={2019},
  eprint={1912.06680},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/1912.06680}
}

@article{jaderberg2019human,
	author = {Jaderberg, Max and Czarnecki, Wojciech M. and Dunning, Iain and Marris, Luke and Lever, Guy and Casta{\~n}eda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C. and Morcos, Ari S. and Ruderman, Avraham and Sonnerat, Nicolas and Green, Tim and Deason, Louise and Leibo, Joel Z. and Silver, David and Hassabis, Demis and Kavukcuoglu, Koray and Graepel, Thore},
	title = {Human-level Performance in {3D} Multiplayer Games with Population-based Reinforcement Learning},
	volume = {364},
	number = {6443},
	pages = {859--865},
	year = {2019},
	doi = {10.1126/science.aau6249},
	publisher = {American Association for the Advancement of Science},
	abstract = {Artificially intelligent agents are getting better and better at two-player games, but most real-world endeavors require teamwork. Jaderberg et al. designed a computer program that excels at playing the video game Quake III Arena in Capture the Flag mode, where two multiplayer teams compete in capturing the flags of the opposing team. The agents were trained by playing thousands of games, gradually learning successful strategies not unlike those favored by their human counterparts. Computer agents competed successfully against humans even when their reaction times were slowed to match those of humans.Science, this issue p. 859Reinforcement learning (RL) has shown great success in increasingly complex single-agent environments and two-player turn-based games. However, the real world contains multiple agents, each learning and acting independently to cooperate and compete with other agents. We used a tournament-style evaluation to demonstrate that an agent can achieve human-level performance in a three-dimensional multiplayer first-person video game, Quake III Arena in Capture the Flag mode, using only pixels and game points scored as input. We used a two-tier optimization process in which a population of independent RL agents are trained concurrently from thousands of parallel matches on randomly generated environments. Each agent learns its own internal reward signal and rich representation of the world. These results indicate the great potential of multiagent reinforcement learning for artificial intelligence research.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/364/6443/859},
	eprint = {https://science.sciencemag.org/content/364/6443/859.full.pdf},
	journal = {Science}
}

@article{moravcik2017deepstack,
	author = {Morav{\v c}{\'\i}k, Matej and Schmid, Martin and Burch, Neil and Lis{\'y}, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
	title = {{D}eep{S}tack: Expert-level Artificial Intelligence in Heads-up No-limit Poker},
	volume = {356},
	number = {6337},
	pages = {508--513},
	year = {2017},
	doi = {10.1126/science.aam6960},
	publisher = {American Association for the Advancement of Science},
	abstract = {Computers can beat humans at games as complex as chess or go. In these and similar games, both players have access to the same information, as displayed on the board. Although computers have the ultimate poker face, it has been tricky to teach them to be good at poker, where players cannot see their opponents{\textquoteright} cards. Morav{\v c}{\'\i}k et al. built a code dubbed DeepStack that managed to beat professional poker players at a two-player poker variant called heads-up no-limit Texas hold{\textquoteright}em. Instead of devising its strategy beforehand, DeepStack recalculated it at each step, taking into account the current state of the game. The principles behind DeepStack may enable advances in solving real-world problems that involve information asymmetry.Science, this issue p. 508Artificial intelligence has seen several breakthroughs in recent years, with games often serving as milestones. A common feature of these games is that players have perfect information. Poker, the quintessential game of imperfect information, is a long-standing challenge problem in artificial intelligence. We introduce DeepStack, an algorithm for imperfect-information settings. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. In a study involving 44,000 hands of poker, DeepStack defeated, with statistical significance, professional poker players in heads-up no-limit Texas hold{\textquoteright}em. The approach is theoretically sound and is shown to produce strategies that are more difficult to exploit than prior approaches.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/356/6337/508},
	eprint = {https://science.sciencemag.org/content/356/6337/508.full.pdf},
	journal = {Science}
}

@article{brown2018superhuman,
	author = {Brown, Noam and Sandholm, Tuomas},
	title = {Superhuman AI for Heads-up No-limit Poker: Libratus Beats Top Professionals},
	volume = {359},
	number = {6374},
	pages = {418--424},
	year = {2018},
	doi = {10.1126/science.aao1733},
	publisher = {American Association for the Advancement of Science},
	abstract = {Pitting artificial intelligence (AI) against top human players demonstrates just how far AI has come. Brown and Sandholm built a poker-playing AI called Libratus that decisively beat four leading human professionals in the two-player variant of poker called heads-up no-limit Texas hold{\textquoteright}em (HUNL). Over nearly 3 weeks, Libratus played 120,000 hands of HUNL against the human professionals, using a three-pronged approach that included precomputing an overall strategy, adapting the strategy to actual gameplay, and learning from its opponent.Science, this issue p. 418No-limit Texas hold{\textquoteright}em is the most popular form of poker. Despite artificial intelligence (AI) successes in perfect-information games, the private information and massive game tree have made no-limit poker difficult to tackle. We present Libratus, an AI that, in a 120,000-hand competition, defeated four top human specialist professionals in heads-up no-limit Texas hold{\textquoteright}em, the leading benchmark and long-standing challenge problem in imperfect-information game solving. Our game-theoretic approach features application-independent techniques: an algorithm for computing a blueprint for the overall strategy, an algorithm that fleshes out the details of the strategy for subgames that are reached during play, and a self-improver algorithm that fixes potential weaknesses that opponents have identified in the blueprint strategy.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/359/6374/418},
	eprint = {https://science.sciencemag.org/content/359/6374/418.full.pdf},
	journal = {Science}
}

@unpublished{lim2021voronoi,
      title={Voronoi Progressive Widening: Efficient Online Solvers for Continuous Space {MDP}s and {POMDP}s with Provably Optimal Components}, 
      author={Michael H. Lim and Claire J. Tomlin and Zachary N. Sunberg},
      year={2021},
      booktitle=icaps,
      note={Under Review for ICAPS 2021}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S. and Barto, Andrew G.},
  year={2018},
  publisher={MIT press}
}

@inproceedings{mania2019certainty,
 author = {Mania, Horia and Tu, Stephen and Recht, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 publisher = {Curran Associates, Inc.},
 title = {Certainty Equivalence is Efficient for Linear Quadratic Control},
 url = {https://proceedings.neurips.cc/paper/2019/file/5dbc8390f17e019d300d5a162c3ce3bc-Paper.pdf},
 volume = {32},
 year = {2019}
}

@book{kochenderfer2019algorithms,
  title={Algorithms for Optimization},
  author={Kochenderfer, Mykel J. and Wheeler, Tim A.},
  year={2019},
  publisher={{MIT} Press}
}

@article{cai2020hyp,
  title={{HyP-DESPOT}: A Hybrid Parallel Algorithm for Online Planning under Uncertainty},
  author={Cai, Panpan and Luo, Yuanfu and Hsu, David and Lee, Wee Sun},
  journal={The International Journal of Robotics Research},
  pages={0278364920937074},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{lee2020magic,
  title={{MAGIC}: Learning Macro-Actions for Online {POMDP} Planning using Generator-Critic},
  author={Lee, Yiyuan and Cai, Panpan and Hsu, David},
  journal={arXiv preprint arXiv:2011.03813},
  year={2020}
}

@article{luo2018importance,
author = {Yuanfu Luo and Haoyu Bai and David Hsu and Wee Sun Lee},
title ={Importance sampling for online planning under uncertainty},
journal = {The International Journal of Robotics Research},
volume = {38},
number = {2-3},
pages = {162-181},
year = {2019},
doi = {10.1177/0278364918780322},

URL = { 
        https://doi.org/10.1177/0278364918780322
    
},
eprint = { 
        https://doi.org/10.1177/0278364918780322
    
}
,
    abstract = { The partially observable Markov decision process (POMDP) provides a principled general framework for robot planning under uncertainty. Leveraging the idea of Monte Carlo sampling, recent POMDP planning algorithms have scaled up to various challenging robotic tasks, including, real-time online planning for autonomous vehicles. To further improve online planning performance, this paper presents IS-DESPOT, which introduces importance sampling to DESPOT, a state-of-the-art sampling-based POMDP algorithm for planning under uncertainty. Importance sampling improves DESPOT’s performance when there are critical, but rare events, which are difficult to sample. We prove that IS-DESPOT retains the theoretical guarantee of DESPOT. We demonstrate empirically that importance sampling significantly improves the performance of online POMDP planning for suitable tasks. We also present a general method for learning the importance sampling distribution. }
}

@article{kaelbling1998planning,
  title={Planning and Acting in Partially Observable Stochastic Domains},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
  journal={Artificial intelligence},
  volume={101},
  number={1-2},
  pages={99--134},
  year={1998},
  publisher={Elsevier}
}

@inproceedings{araya2010pomdp,
  title={A {POMDP} Extension with Belief-dependent Rewards},
  author={Araya-L{\'o}pez, Mauricio and Buffet, Olivier and Thomas, Vincent and Charpillet, Fran{\c{c}}ois},
  booktitle=nips,
  year={2010},
  organization={MIT Press}
}

@inproceedings{bouton2018scalable,
  title={Scalable Decision Making with Sensor Occlusions for Autonomous Driving},
  author={Bouton, Maxime and Nakhaei, Alireza and Fujimura, Kikuo and Kochenderfer, Mykel J},
  booktitle=icra,
  pages={2076--2081},
  year={2018},
  organization={IEEE}
}

@inproceedings{thornton2018value,
  title={Value Sensitive Design for Autonomous Vehicle Motion Planning},
  author={Thornton, Sarah M and Lewis, Francis E and Zhang, Vivian and Kochenderfer, Mykel J and Gerdes, J Christian},
  booktitle={{IEEE} Intelligent Vehicles Symposium (IV)},
  pages={1157--1162},
  year={2018},
  organization={IEEE}
}

@article{akbarinasaji2020partially,
title = {Partially observable Markov decision process to generate policies in software defect management},
journal = {Journal of Systems and Software},
volume = {163},
pages = {110518},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110518},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300017},
author = {Shirin Akbarinasaji and Can Kavaklioglu and Ayşe Başar and Adam Neal},
keywords = {Defect management, Policy, Reinforcement learning, Partially observable Markov decision Process, Partially observable Monte Carlo Planning},
abstract = {Bug repositories are dynamic in nature and as new bugs arrive, the old ones are closed. In a typical software project, bugs and their dependencies are reported manually and gradually using a issue tracking system. Thus, not all of the bugs in the system are available at any time, creating uncertainty in the dependency structure of the bugs. In this research, we propose to construct a dependency graph based on the reported dependency-blocking information in a issue tracking system. We use two graph metrics, depth and degree, to measure the extent of blocking bugs. Due to the uncertainty in the dependency structure, simply ordering bugs in the descending order of depth and/or degree may not be the best policy to prioritize bugs. Instead, we propose a Partially Observable Markov Decision Process model for sequential decision making and Partially Observable Monte Carlo Planning to identify the best policy for this sequential decision-making process. We validated our proposed approach by mining the data from two open source projects, and a commercial project. We compared our proposed framework with three baseline policies. The results on all datasets show that our proposed model significantly outperforms the other policies with respect to average discounted return.}
}

@INPROCEEDINGS{tomin2019intelligent,
  author={Tomin, Nikita and Kurbatsky, Victor and Guliyev, Huseyngulu},
  booktitle={Conference on Electrical Machines, Drives and Power Systems ({ELMA})}, 
  title={Intelligent Control of a Wind Turbine based on Reinforcement Learning}, 
  year={2019},
  pages={1-6},
  doi={10.1109/ELMA.2019.8771645}
}

@inproceedings{linares2016dynamic,
  title={Dynamic Sensor Tasking for Space Situational Awareness via Reinforcement Learning},
  author={Linares, Richard and Furfaro, Roberto},
  booktitle={Advanced Maui Optical and Space Surveillance Tech. Conf.(AMOS)},
  year={2016}
}

@article{metz2021costly,
    title={The Costly Pursuit of Self-Driving Cars Continues On. And On. And On.},
    author={Metz, Cade},
    journal={The New York Times},
    year={2021},
    date={2021-05-24},
    url={https://www.nytimes.com/2021/05/24/technology/self-driving-cars-wait.html}
}

@inproceedings{burghouts2020competence,
  title={Robotic Self-Assessment of Competence},
  author={Burghouts, Gertjan J and Huizing, Albert and Neerincx, Mark A},
  url={https://arxiv.org/abs/2005.01546},
  year={2020}
}

@article{devisser2020trust,
  title={Towards a theory of longitudinal trust calibration in human--robot teams},
  author={De Visser, Ewart J and Peeters, Marieke MM and Jung, Malte F and Kohn, Spencer and Shaw, Tyler H and Pak, Richard and Neerincx, Mark A},
  journal={International journal of social robotics},
  volume={12},
  number={2},
  pages={459--478},
  year={2020},
  publisher={Springer}
}

@inproceedings{basich2020learning,
  title={Learning to Optimize Autonomy in Competence-Aware Systems},
  author={Basich, Connor and Svegliato, Justin and Wray, Kyle Hollins and Witwicki, Stefan and Biswas, Joydeep and Zilberstein, Shlomo},
  booktitle=aamas,
  pages={123--131},
  year={2020}
}

@article{hawes2017strands,
  title={The {STRANDS} project: Long-term autonomy in everyday environments},
  author={Hawes, Nick and Burbridge, Christopher and Jovan, Ferdian and Kunze, Lars and Lacerda, Bruno and Mudrova, Lenka and Young, Jay and Wyatt, Jeremy and Hebesberger, Denise and Kortner, Tobias and others},
  journal={IEEE Robotics \& Automation Magazine},
  volume={24},
  number={3},
  pages={146--156},
  year={2017},
  publisher={IEEE}
}

@inproceedings{svegliato2019belief,
  title={Belief space metareasoning for exception recovery},
  author={Svegliato, Justin and Wray, Kyle Hollins and Witwicki, Stefan J and Biswas, Joydeep and Zilberstein, Shlomo},
  booktitle=iros,
  pages={1224--1229},
  year={2019},
  organization={IEEE}
}

@article{alterovitz2016robot,
  title={Robot planning in the real world: research challenges and opportunities},
  author={Alterovitz, Ron and Koenig, Sven and Likhachev, Maxim},
  journal={Ai Magazine},
  volume={37},
  number={2},
  pages={76--84},
  year={2016}
}

@article{basich2020improving,
  title={Improving Competence for Reliable Autonomy},
  author={Basich, Connor and Svegliato, Justin and Wray, Kyle Hollins and Witwicki, Stefan J and Zilberstein, Shlomo},
  journal={arXiv preprint arXiv:2007.11740},
  year={2020}
}

@inproceedings{schmerling2018multimodal,
  title={Multimodal probabilistic model-based planning for human-robot interaction},
  author={Schmerling, Edward and Leung, Karen and Vollprecht, Wolf and Pavone, Marco},
  booktitle=icra,
  pages={3399--3406},
  year={2018},
  organization={IEEE}
}

% Begin object-oriented

@inproceedings{diuk2008object,
  title={An Object-oriented Representation for Efficient Reinforcement Learning},
  author={Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
  booktitle={Proceedings of the 25th International Conference on Machine learning},
  pages={240--247},
  year={2008}
}

@inproceedings{cobo2013object,
  title={Object focused q-learning for autonomous agents},
  author={Cobo, Luis C and Isbell Jr, Charles L and Thomaz, Andrea L},
  year={2013},
  organization={Georgia Institute of Technology}
}

% OO-POMCP
@inproceedings{wandzel2019multi,
  title={Multi-object Search using Object-oriented {POMDP}s},
  author={Wandzel, Arthur and Oh, Yoonseon and Fishman, Michael and Kumar, Nishanth and Wong, Lawson LS and Tellex, Stefanie},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={7194--7200},
  year={2019},
  organization={IEEE}
}


@InProceedings{zhang2018composable,
  title = 	 {Composable Planning with Attributes},
  author =       {Zhang, Amy and Sukhbaatar, Sainbayar and Lerer, Adam and Szlam, Arthur and Fergus, Rob},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {5842--5851},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/zhang18k/zhang18k.pdf},
  url = 	 {http://proceedings.mlr.press/v80/zhang18k.html},
  abstract = 	 {The tasks that an agent will need to solve often are not known during training. However, if the agent knows which properties of the environment are important then, after learning how its actions affect those properties, it may be able to use this knowledge to solve complex tasks without training specifically for them. Towards this end, we consider a setup in which an environment is augmented with a set of user defined attributes that parameterize the features of interest. We propose a method that learns a policy for transitioning between “nearby” sets of attributes, and maintains a graph of possible transitions. Given a task at test time that can be expressed in terms of a target set of attributes, and a current state, our model infers the attributes of the current state and searches over paths through attribute space to get a high level plan, and then uses its low level policy to execute the plan. We show in 3D block stacking, grid-world games, and StarCraft that our model is able to generalize to longer, more complex tasks at test time by composing simpler learned policies.}
}

@phdthesis{walsh2010efficient,
  title={Efficient learning of relational models for sequential decision making},
  author={Walsh, Thomas J},
  year={2010},
  school={Rutgers University-Graduate School-New Brunswick}
}

@Inbook{vanotterlo2012relational,
author="van Otterlo, Martijn",
editor="Wiering, Marco
and van Otterlo, Martijn",
title="Solving Relational and First-Order Logical Markov Decision Processes: A Survey",
bookTitle="Reinforcement Learning: State-of-the-Art",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="253--292",
abstract="In this chapter we survey representations and techniques for Markov decision processes, reinforcement learning, and dynamic programming in worlds explicitly modeled in terms of objects and relations. Such relational worlds can be found everywhere in planning domains, games, real-world indoor scenes and many more. Relational representations allow for expressive and natural datastructures that capture the objects and relations in an explicit way, enabling generalization over objects and relations, but also over similar problems which differ in the number of objects. The field was recently surveyed completely in (van Otterlo, 2009b), and here we describe a large portion of the main approaches. We discuss model-free -- both value-based and policy-based -- and model-based dynamic programming techniques. Several other aspects will be covered, such as models and hierarchies, and we end with several recent efforts and future directions.",
isbn="978-3-642-27645-3",
doi="10.1007/978-3-642-27645-3_8",
url="https://doi.org/10.1007/978-3-642-27645-3_8"
}

@inproceedings{topin2015portable,
  title={Portable Option Discovery for Automated Learning Transfer in Object-Oriented {M}arkov Decision Processes},
  author={Topin, Nicholay and Haltmeyer, Nicholas and Squire, Shawn and Winder, John and desJardins, Marie and MacGlashan, James},
  booktitle=ijcai,
  year={2015}
}

@article{franklin2018compositional,
  title={Compositional clustering in task structure learning},
  author={Franklin, Nicholas T and Frank, Michael J},
  journal={PLoS computational biology},
  volume={14},
  number={4},
  pages={e1006116},
  year={2018},
  publisher={Public Library of Science}
}

% Learning (from pixels?)
@inproceedings{zhu2018object,
  title={Object-oriented dynamics predictor},
  author={Zhu, Guangxiang and Huang, Zhiao and Zhang, Chongjie},
  booktitle=neurips,
  pages={9826--9837},
  year={2018}
}

% More structure/composition speeds up, MCTS outperforms other RL
@InProceedings{bapst2019structured,
  title = 	 {Structured agents for physical construction},
  author =       {Bapst, Victor and Sanchez-Gonzalez, Alvaro and Doersch, Carl and Stachenfeld, Kimberly and Kohli, Pushmeet and Battaglia, Peter and Hamrick, Jessica},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {464--474},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/bapst19a/bapst19a.pdf},
  url = 	 {
http://proceedings.mlr.press/v97/bapst19a.html
},
  abstract = 	 {Physical construction—the ability to compose objects, subject to physical dynamics, to serve some function—is fundamental to human intelligence. We introduce a suite of challenging physical construction tasks inspired by how children play with blocks, such as matching a target configuration, stacking blocks to connect objects together, and creating shelter-like structures over target objects. We examine how a range of deep reinforcement learning agents fare on these challenges, and introduce several new approaches which provide superior performance. Our results show that agents which use structured representations (e.g., objects and scene graphs) and structured policies (e.g., object-centric actions) outperform those which use less structured representations, and generalize better beyond their training when asked to reason about larger scenes. Model-based agents which use Monte-Carlo Tree Search also outperform strictly model-free agents in our most challenging construction problems. We conclude that approaches which combine structured representations and reasoning with powerful learning are a key path toward agents that possess rich intuitive physics, scene understanding, and planning.}
}


@INPROCEEDINGS{woof2018learning,
  author={Woof, William and Chen, Ke},
  booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)}, 
  title={Learning to Play General Video-Games via an Object Embedding Network}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/CIG.2018.8490438}}


@inproceedings{braylan2016object,
  title={Object-model transfer in the general video game domain},
  author={Braylan, Alexander and Miikkulainen, Risto},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={12},
  number={1},
  year={2016}
}

% learning, MCTS outperforms
@article{keramati2018fast,
  title={Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning},
  author={Keramati, Ramtin and Whang, Jay and Cho, Patrick and Brunskill, Emma},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@article{van2019perspective,
  title={A perspective on objects and systematic generalization in model-based rl},
  author={van Steenkiste, Sjoerd and Greff, Klaus and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1906.01035},
  year={2019}
}

% able to build more complicated block towers than in training
@inproceedings{janner2019reasoning,
  title={Reasoning about physical interactions with object-oriented prediction and planning},
  author={Janner, Michael and Levine, Sergey and Freeman, William T and Tenenbaum, Joshua B and Finn, Chelsea and Wu, Jiajun},
  year={2019},
  organization={International Conference on Learning Representations}
}

% mentions interpretability
@inproceedings{crawford2019spatially,
  title={Spatially invariant unsupervised object detection with convolutional neural networks},
  author={Crawford, Eric and Pineau, Joelle},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3412--3420},
  year={2019}
}

% learning
@article{goel2018unsupervised,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Goel, Vikash and Weng, Jameson and Poupart, Pascal},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={5683--5694},
  year={2018}
}

% learning to do complicated things with objects
@inproceedings{baker2019emergent,
  title={Emergent Tool Use From Multi-Agent Autocurricula},
  author={Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{zambaldi2018deep,
title={Deep reinforcement learning with relational inductive biases},
author={Vinicius Zambaldi and David Raposo and Adam Santoro and Victor Bapst and Yujia Li and Igor Babuschkin and Karl Tuyls and David Reichert and Timothy Lillicrap and Edward Lockhart and Murray Shanahan and Victoria Langston and Razvan Pascanu and Matthew Botvinick and Oriol Vinyals and Peter Battaglia},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HkxaFoC9KQ},
}

@inproceedings{dubey2018investigating,
  title={Investigating Human Priors for Playing Video Games},
  author={Dubey, Rachit and Agrawal, Pulkit and Pathak, Deepak and Griffiths, Tom and Efros, Alexei},
  booktitle={International Conference on Machine Learning},
  pages={1349--1357},
  year={2018},
  organization={PMLR}
}

@InProceedings{scholz2014physics,
  title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
  author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
  booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
  pages = 	 {1089--1097},
  year = 	 {2014},
  editor = 	 {Eric P. Xing and Tony Jebara},
  volume = 	 {32},
  number =       {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Bejing, China},
  month = 	 {22--24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v32/scholz14.pdf},
  url = 	 {http://proceedings.mlr.press/v32/scholz14.html},
  abstract = 	 {One of the key challenges in using reinforcement learning in robotics is the need for models that capture natural world structure. There are, methods that formalize multi-object dynamics using relational representations, but these methods are not sufficiently compact for  real-world robotics. We present a physics-based approach that exploits modern simulation tools to efficiently parameterize physical dynamics.  Our results show that this representation can result in much faster learning, by virtue of its strong but appropriate inductive bias in  physical environments.}
}

% end object oriented

@article{kerry2017gauging,
    title = {Gauging Investment in Self-Driving Cars},
    author = {Kerry, Cameron F. and Karsten, Jack},
    journal = {Brookings},
    year = {2017},
    date = {2017-10-16},
    url = {https://www.brookings.edu/research/gauging-investment-in-self-driving-cars/}
}

@book{lavalle2006planning,
  title={Planning algorithms},
  author={LaValle, Steven M},
  year={2006},
  publisher={Cambridge university press}
}

@inproceedings{zolfaghari2018eco,
  title={Eco: Efficient convolutional network for online video understanding},
  author={Zolfaghari, Mohammadreza and Singh, Kamaljeet and Brox, Thomas},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={695--712},
  year={2018}
}

@inproceedings{wu2017squeezedet,
  title={Squeezedet: Unified, small, low power fully convolutional neural networks for real-time object detection for autonomous driving},
  author={Wu, Bichen and Iandola, Forrest and Jin, Peter H and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={129--137},
  year={2017}
}

@inproceedings{doucett2000rao,
    author = {Doucett, Arnaud and Freitast, Nando De and Russent, Stuart},
    title = {{Rao-Blackwellised Particle Filtering for Dynamic Bayesian Networks}},
    booktitle = uai,
    year = {2000}
}

@article{karkus2019differentiable,
  title={Differentiable algorithm networks for composable robot learning},
  author={Karkus, Peter and Ma, Xiao and Hsu, David and Kaelbling, Leslie Pack and Lee, Wee Sun and Lozano-P{\'e}rez, Tom{\'a}s},
  journal={arXiv preprint arXiv:1905.11602},
  year={2019}
}

@inproceedings{bojarski2016end,
  title={End to End Learning for Self-Driving Cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol},
  booktitle=cvpr,
  year={2016}
}


@book{thrun2005probabilistic,
  title={Probabilistic Robotics},
  author={Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
  year={2005},
  publisher={The MIT Press}
}

@INPROCEEDINGS{jonschkowski2018differentiable, 
    AUTHOR    = {Rico Jonschkowski AND Divyam Rastogi AND Oliver Brock}, 
    TITLE     = {Differentiable Particle Filters: End-to-End Learning with Algorithmic Priors}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2018}, 
    ADDRESS   = {Pittsburgh, Pennsylvania}, 
    MONTH     = {June}, 
    DOI       = {10.15607/RSS.2018.XIV.001} 
} 

@inproceedings{bansal2017hamilton,
  title={Hamilton-Jacobi reachability: A brief overview and recent advances},
  author={Bansal, Somil and Chen, Mo and Herbert, Sylvia and Tomlin, Claire J},
  booktitle={2017 IEEE 56th Annual Conference on Decision and Control (CDC)},
  pages={2242--2253},
  year={2017},
  organization={IEEE}
}

@inproceedings{alshiekh2018safe,
  title={Safe reinforcement learning via shielding},
  author={Alshiekh, Mohammed and Bloem, Roderick and Ehlers, R{\"u}diger and K{\"o}nighofer, Bettina and Niekum, Scott and Topcu, Ufuk},
  booktitle=aaai,
  volume={32},
  number={1},
  year={2018}
}


@InProceedings{hafner2019planet,
  title = 	 {Learning Latent Dynamics for Planning from Pixels},
  author =       {Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2555--2565},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/hafner19a/hafner19a.pdf},
  url = 	 {
http://proceedings.mlr.press/v97/hafner19a.html
},
  abstract = 	 {Planning has been very successful for control tasks with known environment dynamics. To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the world. However, learning dynamics models that are accurate enough for planning has been a long-standing challenge, especially in image-based domains. We propose the Deep Planning Network (PlaNet), a purely model-based agent that learns the environment dynamics from images and chooses actions through fast online planning in latent space. To achieve high performance, the dynamics model must accurately predict the rewards ahead for multiple time steps. We approach this using a latent dynamics model with both deterministic and stochastic transition components. Moreover, we propose a multi-step variational inference objective that we name latent overshooting. Using only pixel observations, our agent solves continuous control tasks with contact dynamics, partial observability, and sparse rewards, which exceed the difficulty of tasks that were previously solved by planning with learned models. PlaNet uses substantially fewer episodes and reaches final performance close to and sometimes higher than strong model-free algorithms.}
}

@InProceedings{gautam2021self,
author="Gautam, Alvika
and Crandall, Jacob W.
and Goodrich, Michael A.",
editor="Zallio, Matteo",
title="Self-assessment of Proficiency of Intelligent Systems: Challenges and Opportunities",
booktitle="Advances in Human Factors in Robots, Drones and Unmanned Systems",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="108--113",
abstract="Autonomous systems, although capable of performing complicated tasks much faster than humans, are brittle due to uncertainties encountered in most real-time applications. People supervising these systems often rely on information relayed by the system to make any decisions, which places a burden on the system to self-assess its proficiency and communicate the relevant information.",
isbn="978-3-030-51758-8"
}

@article{julian2019verifying,
  title={Verifying aircraft collision avoidance neural networks through linear approximations of safe regions},
  author={Julian, Kyle D and Sharma, Shivam and Jeannin, Jean-Baptiste and Kochenderfer, Mykel J},
  journal={arXiv preprint arXiv:1903.00762},
  year={2019}
}

@inproceedings{ahmad2021probabilistic,
    author={Ahmad, Shakeeb G. and Sunberg, Zachary and Humbert, Sean},
    author+an={2=me},
    title={{APF-PF}: Probabilistic Depth Perception for {3D} Reactive Obstacle Avoidance},
    year=2021,
    booktitle={American Control Conference (ACC)}
}


@ARTICLE{kschischang2001factor,
  author={Kschischang, F.R. and Frey, B.J. and Loeliger, H.-A.},
  journal={IEEE Transactions on Information Theory}, 
  title={Factor graphs and the sum-product algorithm}, 
  year={2001},
  volume={47},
  number={2},
  pages={498-519},
  doi={10.1109/18.910572}}

% BEGIN OOD

@article{ren2019likelihood,
  title={Likelihood Ratios for Out-of-Distribution Detection},
  author={Ren, Jie and Liu, Peter J and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and Depristo, Mark and Dillon, Joshua and Lakshminarayanan, Balaji},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={14707--14718},
  year={2019}
}

@inproceedings{moller2021out,
  title={Out-of-distribution Detection and Generation using Soft Brownian Offset Sampling and Autoencoders},
  author={Moller, Felix and Botache, Diego and Huseljic, Denis and Heidecker, Florian and Bieshaar, Maarten and Sick, Bernhard},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={46--55},
  year={2021}
}

@misc{fort2021exploring,
      title={Exploring the Limits of Out-of-Distribution Detection}, 
      author={Stanislav Fort and Jie Ren and Balaji Lakshminarayanan},
      year={2021},
      eprint={2106.03004},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{liang2018enhancing,
  title={Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks},
  author={Liang, Shiyu and Li, Yixuan and Srikant, R},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{lee2018simple,
  title={A simple unified framework for detecting out-of-distribution samples and adversarial attacks},
  author={Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{choi2018waic,
  title={{WAIC}, but why? generative ensembles for robust anomaly detection},
  author={Choi, Hyunsun and Jang, Eric and Alemi, Alexander A},
  journal={arXiv preprint arXiv:1810.01392},
  year={2018}
}

@article{lakshminarayanan2017simple,
  title={Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{bock2020ind,
  title={The {IND} Dataset: A Drone Dataset Of Naturalistic Road User Trajectories at {G}erman Intersections},
  author={Bock, Julian and Krajewski, Robert and Moers, Tobias and Runde, Steffen and Vater, Lennart and Eckstein, Lutz},
  booktitle={2020 IEEE Intelligent Vehicles Symposium (IV)},
  pages={1929--1934},
  year={2020},
  organization={IEEE}
}

@article{armeni2017joint,
  title={Joint 2d-3d-semantic data for indoor scene understanding},
  author={Armeni, Iro and Sax, Sasha and Zamir, Amir R and Savarese, Silvio},
  journal={arXiv preprint arXiv:1702.01105},
  year={2017}
}

@inproceedings{pineau2003point,
  title={Point-based value iteration: An anytime algorithm for {POMDP}s},
  author={Pineau, Joelle and Gordon, Geoff and Thrun, Sebastian},
  booktitle={IJCAI},
  volume={3},
  pages={1025--1032},
  year={2003},
  organization={Citeseer}
}

@article{spaan2005perseus,
  title={Perseus: Randomized point-based value iteration for {POMDP}s},
  author={Spaan, Matthijs TJ and Vlassis, Nikos},
  journal={Journal of artificial intelligence research},
  volume={24},
  pages={195--220},
  year={2005}
}

@incollection{bai2010monte,
  title={{M}onte {C}arlo value iteration for continuous-state {POMDP}s},
  author={Bai, Haoyu and Hsu, David and Lee, Wee Sun and Ngo, Vien A},
  booktitle={Algorithmic foundations of robotics IX},
  pages={175--191},
  year={2010},
  publisher={Springer}
}

@article{barto1995learning,
  title={Learning to act using real-time dynamic programming},
  author={Barto, Andrew G and Bradtke, Steven J and Singh, Satinder P},
  journal={Artificial intelligence},
  volume={72},
  number={1-2},
  pages={81--138},
  year={1995},
  publisher={Elsevier}
}

@article{zhao2020meld,
  title={MELD: Meta-Reinforcement Learning from Images via Latent State Models},
  author={Zhao, Tony Z and Nagabandi, Anusha and Rakelly, Kate and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.13957},
  year={2020}
}

@article{schrittwieser2021online,
  title={Online and offline reinforcement learning by planning with a learned model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:2104.06294},
  year={2021}
}

@inproceedings{schmeckpeper2020learning,
  title={Learning predictive models from observation and interaction},
  author={Schmeckpeper, Karl and Xie, Annie and Rybkin, Oleh and Tian, Stephen and Daniilidis, Kostas and Levine, Sergey and Finn, Chelsea},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XX 16},
  pages={708--725},
  year={2020},
  organization={Springer}
}

@article{chen2021learning,
  title={Learning Generalizable Robotic Reward Functions from" In-The-Wild" Human Videos},
  author={Chen, Annie S and Nair, Suraj and Finn, Chelsea},
  journal={arXiv preprint arXiv:2103.16817},
  year={2021}
}

@article{chevalier2019robo,
  title={Robo-PlaNet: Learning to Poke in a Day},
  author={Chevalier-Boisvert, Maxime and Alain, Guillaume and Golemo, Florian and Nowrouzezahrai, Derek},
  journal={arXiv preprint arXiv:1911.03594},
  year={2019}
}

@inproceedings{haarnoja2018composable,
  title={Composable deep reinforcement learning for robotic manipulation},
  author={Haarnoja, Tuomas and Pong, Vitchyr and Zhou, Aurick and Dalal, Murtaza and Abbeel, Pieter and Levine, Sergey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={6244--6251},
  year={2018},
  organization={IEEE}
}

@article{humplik2019meta,
  title={Meta reinforcement learning as task inference},
  author={Humplik, Jan and Galashov, Alexandre and Hasenclever, Leonard and Ortega, Pedro A and Teh, Yee Whye and Heess, Nicolas},
  journal={arXiv preprint arXiv:1905.06424},
  year={2019}
}

@inproceedings{julian2020validation,
  title={Validation of image-based neural network controllers through adaptive stress testing},
  author={Julian, Kyle D and Lee, Ritchie and Kochenderfer, Mykel J},
  booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@inproceedings{vachovsky2016toward,
  title={Toward more gender diversity in {CS} through an artificial intelligence summer program for high school girls},
  author={Vachovsky, Marie E and Wu, Grace and Chaturapruek, Sorathan and Russakovsky, Olga and Sommer, Richard and Fei-Fei, Li},
  booktitle={Proceedings of the 47th ACM Technical Symposium on Computing Science Education},
  pages={303--308},
  year={2016}
}

@article{stathoulopoulos2019gender,
  title={Gender diversity in {AI} research},
  author={Stathoulopoulos, Konstantinos and Mateos-Garcia, Juan C.},
  journal={Available at SSRN 3428240},
  year={2019}
}

@misc{khan2020state,
    author={Beethika Khan and Carol Robbins and Abigail Okrent},
    title={The State of {US} Science and Engineering},
    year={2020},
    institution={National Science Foundation and National Science Board}
}

@article{kilgore2007considering,
	title = {Considering Context: A Study of First-Year Engineering Students},
	journal = {Journal of Engineering Education},
	author = {Deborah Kilgore and Cynthia J. Atman and Ken Yasuhara and Theresa J. Barker and Andrew Morozov},
	volume = { 96},
	number = {4},
	year = {2007},
	pages = {321-334},
} 

@book{committee2008changing,
	author="{Committee on Public Understanding of Engineering Messages, National Academy of Engineering}",
	year={2008},
	title={Changing the Conversation: Messages for Improving Public Understanding of Engineering},
	publisher={National Academies Press},
	address={Washington, DC},
}

@article{pettigrew2017public,
  title={Why public health should embrace the autonomous car},
  author={Pettigrew, Simone},
  journal={Australian and New Zealand journal of public health},
  volume={41},
  pages={1--3},
  year={2017},
  publisher={Wiley-Blackwell Publishing Asia}
}

@article{truszkowski2006autonomous,
  title={Autonomous and autonomic systems: A paradigm for future space exploration missions},
  author={Truszkowski, Walter F and Hinchey, Michael G and Rash, James L and Rouff, Christopher A},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={36},
  number={3},
  pages={279--291},
  year={2006},
  publisher={IEEE}
}

@article{frew2020field,
  title={Field observation of tornadic supercells by multiple autonomous fixed-wing unmanned aircraft},
  author={Frew, Eric W and Argrow, Brian and Borenstein, Steve and Swenson, Sara and Hirst, C Alexander and Havenga, Henno and Houston, Adam},
  journal={Journal of Field Robotics},
  volume={37},
  number={6},
  pages={1077--1093},
  year={2020},
  publisher={Wiley Online Library}
}

@inproceedings{sadigh2016information,
  title={Information gathering actions over human internal state},
  author={Sadigh, Dorsa and Sastry, S Shankar and Seshia, Sanjit A and Dragan, Anca},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={66--73},
  year={2016},
  organization={IEEE}
}

@article{huang2021visual,
  title={Visual Foresight Tree for Object Retrieval from Clutter with Nonprehensile Rearrangement},
  author={Huang, Baichuan and Han, Shuai D and Yu, Jingjin and Boularias, Abdeslam},
  journal={arXiv preprint arXiv:2105.02857},
  year={2021}
}

@inproceedings{abadi2016tensorflow,
  title={TensorFlow: A System for Large-scale Machine Learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael  and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zhen},
  booktitle={12th {USENIX} symposium on operating systems design and implementation {OSDI} 16)},
  pages={265--283},
  year={2016}
}

@inproceedings{corso2019adaptive,
  title={Adaptive stress testing with reward augmentation for autonomous vehicle validation},
  author={Corso, Anthony and Du, Peter and Driggs-Campbell, Katherine and Kochenderfer, Mykel J},
  booktitle={2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
  pages={163--168},
  year={2019},
  organization={IEEE}
}

@inproceedings{dosovitskiy2017carla,
  title={{CARLA}: An open urban driving simulator},
  author={Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
  booktitle={Conference on robot learning},
  pages={1--16},
  year={2017},
  organization={PMLR}
}

@misc{nhtsa2019fatality,
    url={https://www-fars.nhtsa.dot.gov/Main/index.aspx},
    author={{National Highway Traffic Safety Administration}},
    title={Fatality Analysis Reporting System ({FARS})},
    year=2019
}

@misc{cto2021modernization,
    author={{Office of the Under Secretary of Defense,
Research and Engineering}},
    url={https://www.cto.mil/modernization-priorities/},
    title={Modernization Priorities},
    date=2021
}

@article{wood2017autonomous,
title = {An autonomous control framework for advanced reactors},
journal = {Nuclear Engineering and Technology},
volume = {49},
number = {5},
pages = {896-904},
year = {2017},
issn = {1738-5733},
doi = {https://doi.org/10.1016/j.net.2017.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1738573317304096},
author = {Richard T. Wood and Belle R. Upadhyaya and Dan C. Floyd},
keywords = {Autonomous Control, Instrumentation and Control System, Small Modular Reactor},
}

@article{rossi2018routing,
  title={Routing autonomous vehicles in congested transportation networks: Structural properties and coordination algorithms},
  author={Rossi, Federico and Zhang, Rick and Hindy, Yousef and Pavone, Marco},
  journal={Autonomous Robots},
  volume={42},
  number={7},
  pages={1427--1442},
  year={2018},
  publisher={Springer}
}

@INPROCEEDINGS{tsao2018stochastic,
  author={Tsao, Matthew and Iglesias, Ramon and Pavone, Marco},
  booktitle={2018 21st International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={Stochastic Model Predictive Control for Autonomous Mobility on Demand}, 
  year={2018},
  volume={},
  number={},
  pages={3941-3948},
  doi={10.1109/ITSC.2018.8569459}
}


@article{bigelow2019disabled,
    title={Disabled fail-safe at issue in Uber crash},
    author={Bigelow, Pete},
    journal={Automotive News},
    year={2019},
    date={2019-11-18},
    url={https://www.autonews.com/mobility-report/disabled-fail-safe-issue-uber-crash}
}

@inproceedings{singh2019end,
  title={End-To-End Robotic Reinforcement Learning without Reward Engineering.},
  author={Singh, Avi and Yang, Larry and Finn, Chelsea and Levine, Sergey},
  booktitle=rss,
  year={2019}
}

@article{chiang2019learning,
  title={Learning navigation behaviors end-to-end with autorl},
  author={Chiang, Hao-Tien Lewis and Faust, Aleksandra and Fiser, Marek and Francis, Anthony},
  journal={IEEE Robotics and Automation Letters},
  volume={4},
  number={2},
  pages={2007--2014},
  year={2019},
  publisher={IEEE}
}

@misc{grant2014cvx,
  title={{CVX}: Matlab software for disciplined convex programming, version 2.1},
  author={Grant, Michael and Boyd, Stephen},
  year={2014}
}

@inproceedings{sunberg2021fair,
    title={Fair Senior Capstone Project Teaming based on Skills, Preferences, and Friend Groups},
    author={Sunberg, Zachary and Wingate, Kathryn and Buri, Lara},
    year=2021,
    booktitle={American Society for Engineering Education (ASEE) Annual Conference}
}

@misc{sunberg2021pomdps,
    title={POMDPs.jl and Interactive Assignments in Julia},
    author={Sunberg, Zachary},
    year=2021,
    booktitle={JuliaCon}
}

@inproceedings{quigley2009ros,
  title={{ROS}: An Open-source Robot Operating System},
  author={Quigley, Morgan and Conley, Ken and Gerkey, Brian and Faust, Josh and Foote, Tully and Leibs, Jeremy and Berger, Eric and Wheeler, Rob and Ng, Andrew Y.},
  booktitle={ICRA workshop on open source software},
  volume={3},
  number={3.2},
  pages={5},
  year={2009},
  organization={Kobe, Japan}
}

@inproceedings{wang2020dualsmc,
  title     = {{DualSMC}: Tunneling Differentiable Filtering and Planning under Continuous {POMDP}s},
  author    = {Wang, Yunbo and Liu, Bo and Wu, Jiajun and Zhu, Yuke and Du, Simon S. and Fei-Fei, Li and Tenenbaum, Joshua B.},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  pages     = {4190--4198},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/579},
  url       = {https://doi.org/10.24963/ijcai.2020/579},
}

@article{agha2014firm,
  title={{FIRM}: Sampling-based feedback motion-planning under motion uncertainty and imperfect measurements},
  author={Agha-Mohammadi, Ali-Akbar and Chakravorty, Suman and Amato, Nancy M},
  journal=ijrr,
  volume={33},
  number={2},
  pages={268--304},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{bry2011rapidly,
  title={Rapidly-exploring random belief trees for motion planning under uncertainty},
  author={Bry, Adam and Roy, Nicholas},
  booktitle=icra,
  pages={723--730},
  year={2011},
  organization={IEEE}
}
