# For publications by ADCL members, see https://www.cu-adcl.org/bibliography/our-pubs.bib

@String { aaai        = {AAAI Conference on Artificial Intelligence (AAAI)} }
@String { aamas       = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)} }
@String { acc         = {American Control Conference (ACC)} }
@String { amos        = {Advanced {M}aui Optical and Space Surveillance Technologies Conference}}
@String { atm         = {Air Traffic Management Research and Development Seminar}}
@String { aiaa_info   = {AIAA Infotech@Aerospace Conference} }
@String { aiaa_jacic  = {Journal of Aerospace Computing, Information, and Communication} }
@String { allerton    = {Allerton Conference on Communication, Control, and Compution} }
@String { atio        = {AIAA Aviation Technology, Integration, and Operations Conference (ATIO)} }
@String { cacm        = {Communications of the ACM} }
@String { cav         = {International Conference on Computer-Aided Verification} }
@String { cdc         = {IEEE Conference on Decision and Control (CDC)} }
@String { cvpr        = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)} }
@String { dasc        = {Digital Avionics Systems Conference (DASC)} }
@String { ecml        = {European Conference on Machine Learning (ECML)} }
@String { gnc         = {AIAA Guidance, Navigation, and Control Conference (GNC)} }
@String { icaart      = {International Conference on Agents and Artificial Intelligence (ICAART)} }
@String { icaps       = {International Conference on Automated Planning and Scheduling (ICAPS)} }
@String { icassp      = {International Conference on Acoustics, Speech, and Signal Processing (ICASSP)} }
@String { iclr        = {International Conference on Learning Representations (ICLR)} }
@String { icml        = {International Conference on Machine Learning (ICML)} }
@String { icmla       = {International Conference on Machine Learning and Applications (ICMLA)} }
@String { icra        = {IEEE International Conference on Robotics and Automation (ICRA)} }
@String { icslp       = {International Conference on Spoken Language Processing (ICSLP)} }
@String { ieee_csm    = {IEEE Control Systems Magazine} }
@String { ieee_tc     = {IEEE Transactions on Cybernetics} }
@String { ieee_j_ac   = {IEEE Transactions on Automatic Control} }
@String { ieeeaero    = {IEEE Aerospace Conference} }
@String { ieeeciaig   = {IEEE Transactions on Computational Intelligence and AI in Games} }
@String { ieeecst     = {IEEE Transactions on Control Systems Technology} }
@String { ieeetiv     = {IEEE Transactions on Intelligent Vehicles} }
@String { ieeetac     = {IEEE Transactions on Automatic Control} }
@String { ieeetits    = {IEEE Transactions on Intelligent Transportation Systems} }
@String { ieeetsp     = {IEEE Transactions on Signal Processing} }
@String { ijcai       = {International Joint Conference on Artificial Intelligence (IJCAI)} }
@String { ijrr        = {International Journal of Robotics Research} }
@String { interspeech = {Annual Conference of the International Speech Communication Association (INTERSPEECH)} }
@String { iros        = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)} }
@String { itsc        = {IEEE International Conference on Intelligent Transportation Systems (ITSC)} }
@String { iv          = {IEEE Intelligent Vehicles Symposium (IV)} }
@String { jaamas      = {Journal of Autonomous Agents and Multi-Agent Systems} }
@String { jair        = {Journal of Artificial Intelligence Research} }
@String { jgcd        = {AIAA Journal of Guidance, Control, and Dynamics} }
@String { jmlr        = {Journal of Machine Learning Research} }
@String { jota        = {Journal of Optimization Theory and Applications} }
@String { lion        = {Learning and Intelligent Optimization (LION)} }
@String { mor         = {Mathematics of Operations Research} }
@String { nips        = {Advances in Neural Information Processing Systems (NIPS)} }
@String { neurips     = {Advances in Neural Information Processing Systems (NeurIPS)} }
@String { or          = {Operations Research} }
@String { rss         = {Robotics: Science and Systems} }
@String { sigcomm     = {ACM Special Interest Group on Data Communication (SIGCOMM)} }
@String { tac         = {IEEE Transactions on Automatic Control} }
@String { tacas       = {International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS)} }
@String { taes        = {IEEE Transactions on Aerospace and Electronic Systems} }
@String { uai         = {Conference on Uncertainty in Artificial Intelligence (UAI)} }
@String { hri         = {ACM/IEEE International Conference on Human-Robot Interaction (HRI)} }

@inproceedings{garg2019despotalpha,
  title={{DESPOT}-$\alpha$: Online {POMDP} Planning With Large State And Observation Spaces},
  author={Neha P. Garg and David Hsu and Wee Sun Lee},
  booktitle={Robotics: Science and Systems},
  year={2019}
}

@inproceedings{lee2020monte,
  title={{M}onte-{C}arlo Tree Search in Continuous Action Spaces with Value Gradients},
  author={Lee, Jongmin and Jeon, Wonseok and Kim, Geon-Hyeong and Kim, Kee-Eung},
  booktitle=aaai,
  pages={4561--4568},
  year={2020}
}

@inproceedings{kim2020monte,
  title={Monte Carlo Tree Search in Continuous Spaces Using Voronoi Optimistic Optimization with Regret Bounds.},
  author={Kim, Beomjoon and Lee, Kyungjae and Lim, Sungbin and Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle=aaai,
  pages={9916--9924},
  year={2020}
}


@inproceedings{garg2019learning,
  title={Learning To Grasp Under Uncertainty Using POMDPs},
  author={Garg, Neha P and Hsu, David and Lee, Wee Sun},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={2751--2757},
  year={2019},
  organization={IEEE}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Rafal Józefowicz and Scott Gray and Catherine Olsson and Jakub Pachocki and Michael Petrov and Henrique P.d.O. Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@misc{darpa2020ace,
    title={Broad Agency Announcement: Air Combat Evolution Technical Area 1: Build Combat Autonomy},
    author={Defence Advanced Research Projects Agency (DARPA)},
    year={2020}
}

@article {jaderberg2019quake,
	author = {Jaderberg, Max and Czarnecki, Wojciech M. and Dunning, Iain and Marris, Luke and Lever, Guy and Casta{\~n}eda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C. and Morcos, Ari S. and Ruderman, Avraham and Sonnerat, Nicolas and Green, Tim and Deason, Louise and Leibo, Joel Z. and Silver, David and Hassabis, Demis and Kavukcuoglu, Koray and Graepel, Thore},
	title = {Human-level performance in 3D multiplayer games with population-based reinforcement learning},
	volume = {364},
	number = {6443},
	pages = {859--865},
	year = {2019},
	doi = {10.1126/science.aau6249},
	publisher = {American Association for the Advancement of Science},
	abstract = {Artificially intelligent agents are getting better and better at two-player games, but most real-world endeavors require teamwork. Jaderberg et al. designed a computer program that excels at playing the video game Quake III Arena in Capture the Flag mode, where two multiplayer teams compete in capturing the flags of the opposing team. The agents were trained by playing thousands of games, gradually learning successful strategies not unlike those favored by their human counterparts. Computer agents competed successfully against humans even when their reaction times were slowed to match those of humans.Science, this issue p. 859Reinforcement learning (RL) has shown great success in increasingly complex single-agent environments and two-player turn-based games. However, the real world contains multiple agents, each learning and acting independently to cooperate and compete with other agents. We used a tournament-style evaluation to demonstrate that an agent can achieve human-level performance in a three-dimensional multiplayer first-person video game, Quake III Arena in Capture the Flag mode, using only pixels and game points scored as input. We used a two-tier optimization process in which a population of independent RL agents are trained concurrently from thousands of parallel matches on randomly generated environments. Each agent learns its own internal reward signal and rich representation of the world. These results indicate the great potential of multiagent reinforcement learning for artificial intelligence research.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/364/6443/859},
	eprint = {https://science.sciencemag.org/content/364/6443/859.full.pdf},
	journal = {Science}
}

@Article{kearns2002sparse,
    author="Kearns, Michael and Mansour, Yishay and Ng, Andrew Y.",
    title="A Sparse Sampling Algorithm for Near-Optimal Planning in Large {M}arkov Decision Processes",
    journal="Machine Learning",
    year="2002",
    month="Nov",
    day="01",
    volume="49",
    number="2",
    pages="193--208",
    issn="1573-0565",
}

@article {silver2018alphazero,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters {C}hess, {S}hogi, and {G}o through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	doi = {10.1126/science.aar6404},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/362/6419/1140},
	eprint = {https://science.sciencemag.org/content/362/6419/1140.full.pdf},
	journal = {Science}
}

@inproceedings{silver2010pomcp,
    title = {{M}onte-{C}arlo Planning in Large {POMDP}s},
    author = {Silver, David and Veness, Joel},
    booktitle = {Advances in Neural Information Processing Systems},
    pages = {2164--2172},
    year = {2010},
    url = {http://papers.nips.cc/paper/4031-monte-carlo-planning-in-large-pomdps.pdf}
}

@article{ye2017despot,
  title={{DESPOT}: Online {POMDP} Planning with Regularization},
  author={Ye, Nan and Somani, Adhiraj and Hsu, David and Lee, Wee Sun},
  journal={Journal of Artificial Intelligence Research},
  volume={58},
  pages={231--266},
  year={2017}
}

@inproceedings{seiler2015online,
  title={An online and approximate solver for {POMDP}s with continuous action space},
  author={Seiler, Konstantin M. and Kurniawati, Hanna and Singh, Surya P. N.},
  booktitle=icra,
  pages={2290--2297},
  year={2015},
}
% GPS-ABT

@article{browne2012survey,
  title={A survey of {M}onte {C}arlo tree search methods},
  author={Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  journal={{IEEE} Transactions on Computational Intelligence and {AI} in games},
  volume={4},
  number={1},
  pages={1--43},
  year={2012},
}

@inproceedings{keller2013trial,
  title={Trial-based heuristic tree search for finite horizon MDPs},
  author={Keller, Thomas and Helmert, Malte},
  booktitle={Twenty-Third International Conference on Automated Planning and Scheduling},
  year={2013}
}


@inproceedings{couetoux2011double,
  address = {Rome, Italy},
  annote = {double progressive widening},
  author = {Cou\"{e}toux, A. and Hoock, J.-B. and Sokolovska, N. and Teytaud, O. and Bonnard, N.},
  booktitle = {Learning and Intelligent Optimization},
  mendeley-groups = {UAVCAS,POMDPs,MDPs},
  title = {Continuous Upper Confidence Trees},
  year = {2011}
}

@inproceedings{frank2007hover,
  title={Hover, transition, and level flight control design for a single-propeller indoor airplane},
  author={Frank, Adrian and McGrew, James and Valenti, Mario and Levine, Daniel and How, Jonathan},
  booktitle={AIAA Guidance, Navigation and Control Conference and Exhibit},
  pages={6318},
  year={2007}
}

@book{shaw1985fighter,
  title={Fighter Combat: Tactics and Maneuvering},
  author={Shaw, Robert L.},
  year={1985},
  publisher={Naval Institute Press},
  address={Annapolis}
}

@Article{holland2013optimizing,
  Title                    = {Optimizing the Next Generation Collision Avoidance System for Safe, Suitable, and Acceptable Operational Performance},
  Author                   = {Jessica E. Holland and Mykel J. Kochenderfer and Wesley A. Olson},
  Journal                  = {{A}ir {T}raffic {C}ontrol {Q}uarterly},
  Year                     = {2013},
  Number                   = {3},
  Pages                    = {275-297},
  Volume                   = {21}
}

@inproceedings{cassandra1998survey,
  title={A survey of {POMDP} applications},
  author={Cassandra, Anthony R},
  booktitle={Working notes of {AAAI} 1998 fall symposium on planning with partially observable {M}arkov decision processes},
  year={1998}
}

@article{ayer2012mammography,
  title={A {POMDP} approach to personalize mammography screening decisions},
  author={Ayer, Turgay and Alagoz, Oguzhan and Stout, Natasha K},
  journal={Operations Research},
  volume={60},
  number={5},
  pages={1019--1034},
  year={2012},
  publisher={INFORMS}
}

@inproceedings{wang2018online,
  title={An Online Planner for {POMDP}s with Large Discrete Action Space: A Quantile-Based Approach.},
  author={Wang, Erli and Kurniawati, Hanna and Kroese, Dirk P.},
  booktitle=icaps,
  year={2018}
}

@article{papadimitriou1987complexity,
  title={The Complexity of {M}arkov Decision Processes},
  author={Papadimitriou, Christos H. and Tsitsiklis, John N.},
  journal={Mathematics of Operations Research},
  volume={12},
  number={3},
  pages={441--450},
  year={1987},
  publisher={{INFORMS}}
}

@inproceedings{littman1995learning,
  title={Learning Policies for Partially Observable Environments: Scaling Up},
  author={Littman, M. L. and Cassandra, A. R. and Kaelbling, L. P.},
  booktitle=icml,
  year={1995}
}

@inproceedings{kurniawati2008sarsop,
  title={{SARSOP}: Efficient Point-based {POMDP} Planning by Approximating Optimally Reachable Belief Spaces},
  author={Kurniawati, Hanna and Hsu, David and Lee, Wee Sun},
  booktitle=rss,
  volume={2008},
  year={2008},
}

@techreport{young2020architecture,
  title={Architecture and Information Requirements to Assess and Predict Flight Safety Risks During Highly Autonomous Urban Flight Operations},
  author={Young, Steven and Ancel, Ersin and Moore, Andrew and Dill, Evan and Quach, Cuong and Foster, John and Darafsheh, Kaveh and Smalling, Kyle and Vazquez, Sixto and Evans, Emory and others},
  year={2020},
  institution={NASA},
  number={TM-2020-220440}
}

@book{nas2018aviation,
    title={In-Time Aviation Safety Mangement: Challenges and Research for an Evolving Aviation System},
    author={{National Academies of Sciences, Engineering, and Medicine}},
    publisher={The National Academies Press},
    year={2018},
    doi={10.17226/24962}
}

@book{nasa2019strategic,
    title={{NASA} Aeronautics Strategic Implementation Plan},
    author={{National Aeronautics and Space Administration}},
    year={2019}
}

@inproceedings{bouton2018utility,
  title={Utility Decomposition with Deep Corrections for Scalable Planning under Uncertainty},
  author={Bouton, Maxime and Julian, Kyle and Nakhaei, Alireza and Fujimura, Kikuo and Kochenderfer, Mykel J.},
  booktitle=aamas,
  pages={462--469},
  year={2018}
}

@inproceedings{bouton2020point,
  title={Point-Based Methods for Model Checking in Partially Observable Markov Decision Processes},
  author={Bouton, Maxime and Tumova, Jana and Kochenderfer, Mykel J.},
  booktitle=aaai,
  pages={10061--10068},
  year={2020}
}

@inproceedings{lee2015adaptive,
  title={Adaptive Stress Testing of Airborne Collision Avoidance Systems},
  author={Lee, Ritchie and Kochenderfer, Mykel J. and Mengshoel, Ole J. and Brat, Guillaume P. and Owen, Michael P.},
  booktitle=dasc,
  year={2015},
  organization={{IEEE}}
}

@article{best2019dec,
  title={Dec-{MCTS}: Decentralized Planning for Multi-Robot Active Perception},
  author={Best, Graeme and Cliff, Oliver M. and Patten, Timothy and Mettu, Ramgopal R. and Fitch, Robert},
  journal=ijrr,
  volume={38},
  number={2-3},
  pages={316--337},
  year={2019},
  publisher={SAGE Publications}
}

@techreport{knkt2018accident,
    author={{Komite Nasional Keselamatan Transportasi}},
    title={Aircraft Accident Investigation Report},
    year={2018},
    number={KNKT.18.10.35.04}
}


@Book{kochenderfer2015decision,
  title =         {Decision Making Under Uncertainty: Theory and Application},
  publisher =     {{MIT} Press},
  year =          {2015},
  author =        {Mykel J. Kochenderfer}
}

@article{ross2008online,
  title={Online planning algorithms for {POMDP}s},
  author={Ross, St{\'e}phane and Pineau, Joelle and Paquet, S{\'e}bastien and Chaib-Draa, Brahim},
  journal={Journal of Artificial Intelligence Research},
  volume={32},
  pages={663--704},
  year={2008}
}

@report{bea2012airfrance,
  title={Final report on the accident on 1st June 2009 to the Airbus A330-203 registered F-GZCP operated by Air France flight AF 447 Rio de Janeiro--Paris},
  author={Bureau d’Enqu{\^e}tes et d’Analyses},
  year={2012}
}

@inproceedings{moore2018testing,
  title={Testing enabling technologies for safe {UAS} urban operations},
  author={Moore, Andrew and Balachandran, Swee and Young, Steven D and Dill, Evan T and Logan, Michael J and Glaab, Louis J and Munoz, Cesar and Consiglio, Maria},
  booktitle={2018 Aviation Technology, Integration, and Operations Conference},
  pages={3200},
  year={2018}
}

@inproceedings{consiglio2016icarous,
  title={{ICAROUS}: Integrated configurable algorithms for reliable operations of unmanned systems},
  author={Consiglio, Mar{\'\i}a and Munoz, C{\'e}sar and Hagen, George and Narkawicz, Anthony and Balachandran, Swee},
  booktitle=dasc,
  year={2016}
}

@book{bertsekas1995dynamic,
  title={Dynamic Programming and Optimal Control},
  author={Bertsekas, Dimitri P.},
  year={1995},
  publisher={Athena Scientific}
}

@book{koller2009probabilistic,
  title={Probabilistic Graphical Models: Principles and Techniques},
  author={Koller, Daphne and Friedman, Nir},
  year={2009},
  publisher={MIT press}
}

@article{ferreiro2012application,
  title={Application of {B}ayesian Networks in Prognostics for a New Integrated Vehicle Health Management Concept},
  author={Ferreiro, Susana and Arnaiz, Aitor and Sierra, Basilio and Irigoien, Itziar},
  journal={Expert Systems with Applications},
  volume={39},
  number={7},
  pages={6402--6418},
  year={2012},
  publisher={Elsevier}
}

@article{xu2015data,
  title={Data mining--based intelligent fault diagnostics for integrated system health management to avionics},
  author={Xu, Jiuping and Sun, Kai and Xu, Lei},
  journal={Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability},
  volume={229},
  number={1},
  pages={3--15},
  year={2015},
  publisher={{SAGE} Publications Sage UK: London, England}
}


@inproceedings{hoerger2021online,
  title={An online POMDP solver for continuous observation spaces},
  author={Hoerger, Marcus and Kurniawati, Hanna},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7643--7649},
  year={2021},
  organization={IEEE}
}

@article{vinyals2019grandmaster,
author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M.  and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H.  and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P.  and Jaderberg, Max and Vezhnevets, Alexander S.  and Leblond, R{\'e}mi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L.  and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and W{\"u}nsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
journal={Nature},
year={2019},
month={Nov},
day={01},
volume={575},
number={7782},
pages={350-354},
abstract={Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1--3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8{\%} of officially ranked human players.},
issn={1476-4687},
doi={10.1038/s41586-019-1724-z},
url={https://doi.org/10.1038/s41586-019-1724-z}
}

@misc{darpa2020alpha,
    title={{A}lpha{D}ogfight Trials Foreshadow Future of Human-Machine Symbiosis},
    url={https://www.darpa.mil/news-events/2020-08-26}
}

@article{openai2019dota,
  title={Dota 2 with Large Scale Deep Reinforcement Learning},
  author={OpenAI and Christopher Berner and Greg Brockman and Brooke Chan and Vicki Cheung and Przemysław Dębiak and Christy Dennison and David Farhi and Quirin Fischer and Shariq Hashme and Chris Hesse and Rafal Józefowicz and Scott Gray and Catherine Olsson and Jakub Pachocki and Michael Petrov and Henrique Pondé de Oliveira Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang},
  year={2019},
  eprint={1912.06680},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/1912.06680}
}

@article{jaderberg2019human,
	author = {Jaderberg, Max and Czarnecki, Wojciech M. and Dunning, Iain and Marris, Luke and Lever, Guy and Casta{\~n}eda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C. and Morcos, Ari S. and Ruderman, Avraham and Sonnerat, Nicolas and Green, Tim and Deason, Louise and Leibo, Joel Z. and Silver, David and Hassabis, Demis and Kavukcuoglu, Koray and Graepel, Thore},
	title = {Human-level Performance in {3D} Multiplayer Games with Population-based Reinforcement Learning},
	volume = {364},
	number = {6443},
	pages = {859--865},
	year = {2019},
	doi = {10.1126/science.aau6249},
	publisher = {American Association for the Advancement of Science},
	abstract = {Artificially intelligent agents are getting better and better at two-player games, but most real-world endeavors require teamwork. Jaderberg et al. designed a computer program that excels at playing the video game Quake III Arena in Capture the Flag mode, where two multiplayer teams compete in capturing the flags of the opposing team. The agents were trained by playing thousands of games, gradually learning successful strategies not unlike those favored by their human counterparts. Computer agents competed successfully against humans even when their reaction times were slowed to match those of humans.Science, this issue p. 859Reinforcement learning (RL) has shown great success in increasingly complex single-agent environments and two-player turn-based games. However, the real world contains multiple agents, each learning and acting independently to cooperate and compete with other agents. We used a tournament-style evaluation to demonstrate that an agent can achieve human-level performance in a three-dimensional multiplayer first-person video game, Quake III Arena in Capture the Flag mode, using only pixels and game points scored as input. We used a two-tier optimization process in which a population of independent RL agents are trained concurrently from thousands of parallel matches on randomly generated environments. Each agent learns its own internal reward signal and rich representation of the world. These results indicate the great potential of multiagent reinforcement learning for artificial intelligence research.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/364/6443/859},
	eprint = {https://science.sciencemag.org/content/364/6443/859.full.pdf},
	journal = {Science}
}

@article{moravcik2017deepstack,
	author = {Morav{\v c}ik, Matej and Schmid, Martin and Burch, Neil and Lis{\'y}, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
	title = {{D}eep{S}tack: Expert-level Artificial Intelligence in Heads-up No-limit Poker},
	volume = {356},
	number = {6337},
	pages = {508--513},
	year = {2017},
	doi = {10.1126/science.aam6960},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/356/6337/508},
	eprint = {https://science.sciencemag.org/content/356/6337/508.full.pdf},
	journal = {Science}
}

@article{brown2018superhuman,
	author = {Brown, Noam and Sandholm, Tuomas},
	title = {Superhuman AI for Heads-up No-limit Poker: Libratus Beats Top Professionals},
	volume = {359},
	number = {6374},
	pages = {418--424},
	year = {2018},
	doi = {10.1126/science.aao1733},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/359/6374/418},
	eprint = {https://science.sciencemag.org/content/359/6374/418.full.pdf},
	journal = {Science}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S. and Barto, Andrew G.},
  year={2018},
  publisher={MIT press}
}

@inproceedings{mania2019certainty,
 author = {Mania, Horia and Tu, Stephen and Recht, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 publisher = {Curran Associates, Inc.},
 title = {Certainty Equivalence is Efficient for Linear Quadratic Control},
 url = {https://proceedings.neurips.cc/paper/2019/file/5dbc8390f17e019d300d5a162c3ce3bc-Paper.pdf},
 volume = {32},
 year = {2019}
}

@book{kochenderfer2019algorithms,
  title={Algorithms for Optimization},
  author={Kochenderfer, Mykel J. and Wheeler, Tim A.},
  year={2019},
  publisher={{MIT} Press}
}

@article{cai2020hyp,
  title={{HyP-DESPOT}: A Hybrid Parallel Algorithm for Online Planning under Uncertainty},
  author={Cai, Panpan and Luo, Yuanfu and Hsu, David and Lee, Wee Sun},
  journal={The International Journal of Robotics Research},
  pages={0278364920937074},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{lee2020magic,
  title={{MAGIC}: Learning Macro-Actions for Online {POMDP} Planning using Generator-Critic},
  author={Lee, Yiyuan and Cai, Panpan and Hsu, David},
  journal={arXiv preprint arXiv:2011.03813},
  year={2020}
}

@article{luo2018importance,
author = {Yuanfu Luo and Haoyu Bai and David Hsu and Wee Sun Lee},
title ={Importance sampling for online planning under uncertainty},
journal = {The International Journal of Robotics Research},
volume = {38},
number = {2-3},
pages = {162-181},
year = {2019},
doi = {10.1177/0278364918780322},
URL = { https://doi.org/10.1177/0278364918780322 },
eprint = { https://doi.org/10.1177/0278364918780322 } ,
}

@article{kaelbling1998planning,
  title={Planning and Acting in Partially Observable Stochastic Domains},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
  journal={Artificial intelligence},
  volume={101},
  number={1-2},
  pages={99--134},
  year={1998},
  publisher={Elsevier}
}

@inproceedings{araya2010pomdp,
  title={A {POMDP} Extension with Belief-dependent Rewards},
  author={Araya-L{\'o}pez, Mauricio and Buffet, Olivier and Thomas, Vincent and Charpillet, Fran{\c{c}}ois},
  booktitle=nips,
  year={2010},
  organization={MIT Press}
}

@inproceedings{bouton2018scalable,
  title={Scalable Decision Making with Sensor Occlusions for Autonomous Driving},
  author={Bouton, Maxime and Nakhaei, Alireza and Fujimura, Kikuo and Kochenderfer, Mykel J},
  booktitle=icra,
  pages={2076--2081},
  year={2018},
  organization={IEEE}
}

@inproceedings{thornton2018value,
  title={Value Sensitive Design for Autonomous Vehicle Motion Planning},
  author={Thornton, Sarah M and Lewis, Francis E and Zhang, Vivian and Kochenderfer, Mykel J and Gerdes, J Christian},
  booktitle={{IEEE} Intelligent Vehicles Symposium (IV)},
  pages={1157--1162},
  year={2018},
  organization={IEEE}
}

@article{akbarinasaji2020partially,
title = {Partially observable Markov decision process to generate policies in software defect management},
journal = {Journal of Systems and Software},
volume = {163},
pages = {110518},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110518},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220300017},
author = {Shirin Akbarinasaji and Can Kavaklioglu and Ayşe Başar and Adam Neal},
keywords = {Defect management, Policy, Reinforcement learning, Partially observable Markov decision Process, Partially observable Monte Carlo Planning},
abstract = {Bug repositories are dynamic in nature and as new bugs arrive, the old ones are closed. In a typical software project, bugs and their dependencies are reported manually and gradually using a issue tracking system. Thus, not all of the bugs in the system are available at any time, creating uncertainty in the dependency structure of the bugs. In this research, we propose to construct a dependency graph based on the reported dependency-blocking information in a issue tracking system. We use two graph metrics, depth and degree, to measure the extent of blocking bugs. Due to the uncertainty in the dependency structure, simply ordering bugs in the descending order of depth and/or degree may not be the best policy to prioritize bugs. Instead, we propose a Partially Observable Markov Decision Process model for sequential decision making and Partially Observable Monte Carlo Planning to identify the best policy for this sequential decision-making process. We validated our proposed approach by mining the data from two open source projects, and a commercial project. We compared our proposed framework with three baseline policies. The results on all datasets show that our proposed model significantly outperforms the other policies with respect to average discounted return.}
}

@INPROCEEDINGS{tomin2019intelligent,
  author={Tomin, Nikita and Kurbatsky, Victor and Guliyev, Huseyngulu},
  booktitle={Conference on Electrical Machines, Drives and Power Systems ({ELMA})}, 
  title={Intelligent Control of a Wind Turbine based on Reinforcement Learning}, 
  year={2019},
  pages={1-6},
  doi={10.1109/ELMA.2019.8771645}
}

@inproceedings{linares2016dynamic,
  title={Dynamic Sensor Tasking for Space Situational Awareness via Reinforcement Learning},
  author={Linares, Richard and Furfaro, Roberto},
  booktitle={Advanced Maui Optical and Space Surveillance Tech. Conf.(AMOS)},
  year={2016}
}

@article{metz2021costly,
    title={The Costly Pursuit of Self-Driving Cars Continues On. And On. And On.},
    author={Metz, Cade},
    journal={The New York Times},
    year={2021},
    date={2021-05-24},
    url={https://www.nytimes.com/2021/05/24/technology/self-driving-cars-wait.html}
}

@inproceedings{burghouts2020competence,
  title={Robotic Self-Assessment of Competence},
  author={Burghouts, Gertjan J and Huizing, Albert and Neerincx, Mark A},
  url={https://arxiv.org/abs/2005.01546},
  year={2020}
}

@article{devisser2020trust,
  title={Towards a theory of longitudinal trust calibration in human--robot teams},
  author={De Visser, Ewart J and Peeters, Marieke MM and Jung, Malte F and Kohn, Spencer and Shaw, Tyler H and Pak, Richard and Neerincx, Mark A},
  journal={International journal of social robotics},
  volume={12},
  number={2},
  pages={459--478},
  year={2020},
  publisher={Springer}
}

@inproceedings{basich2020learning,
  title={Learning to Optimize Autonomy in Competence-Aware Systems},
  author={Basich, Connor and Svegliato, Justin and Wray, Kyle Hollins and Witwicki, Stefan and Biswas, Joydeep and Zilberstein, Shlomo},
  booktitle=aamas,
  pages={123--131},
  year={2020}
}

@article{hawes2017strands,
  title={The {STRANDS} project: Long-term autonomy in everyday environments},
  author={Hawes, Nick and Burbridge, Christopher and Jovan, Ferdian and Kunze, Lars and Lacerda, Bruno and Mudrova, Lenka and Young, Jay and Wyatt, Jeremy and Hebesberger, Denise and Kortner, Tobias and others},
  journal={IEEE Robotics \& Automation Magazine},
  volume={24},
  number={3},
  pages={146--156},
  year={2017},
  publisher={IEEE}
}

@inproceedings{svegliato2019belief,
  title={Belief space metareasoning for exception recovery},
  author={Svegliato, Justin and Wray, Kyle Hollins and Witwicki, Stefan J and Biswas, Joydeep and Zilberstein, Shlomo},
  booktitle=iros,
  pages={1224--1229},
  year={2019},
  organization={IEEE}
}

@article{alterovitz2016robot,
  title={Robot planning in the real world: research challenges and opportunities},
  author={Alterovitz, Ron and Koenig, Sven and Likhachev, Maxim},
  journal={Ai Magazine},
  volume={37},
  number={2},
  pages={76--84},
  year={2016}
}

@article{basich2020improving,
  title={Improving Competence for Reliable Autonomy},
  author={Basich, Connor and Svegliato, Justin and Wray, Kyle Hollins and Witwicki, Stefan J and Zilberstein, Shlomo},
  journal={arXiv preprint arXiv:2007.11740},
  year={2020}
}

@inproceedings{schmerling2018multimodal,
  title={Multimodal probabilistic model-based planning for human-robot interaction},
  author={Schmerling, Edward and Leung, Karen and Vollprecht, Wolf and Pavone, Marco},
  booktitle=icra,
  pages={3399--3406},
  year={2018},
  organization={IEEE}
}

% Begin object-oriented

@inproceedings{diuk2008object,
  title={An Object-oriented Representation for Efficient Reinforcement Learning},
  author={Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
  booktitle={Proceedings of the 25th International Conference on Machine learning},
  pages={240--247},
  year={2008}
}

@inproceedings{cobo2013object,
  title={Object focused q-learning for autonomous agents},
  author={Cobo, Luis C and Isbell Jr, Charles L and Thomaz, Andrea L},
  year={2013},
  organization={Georgia Institute of Technology}
}

% OO-POMCP
@inproceedings{wandzel2019multi,
  title={Multi-object Search using Object-oriented {POMDP}s},
  author={Wandzel, Arthur and Oh, Yoonseon and Fishman, Michael and Kumar, Nishanth and Wong, Lawson LS and Tellex, Stefanie},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={7194--7200},
  year={2019},
  organization={IEEE}
}


@InProceedings{zhang2018composable,
  title = 	 {Composable Planning with Attributes},
  author =       {Zhang, Amy and Sukhbaatar, Sainbayar and Lerer, Adam and Szlam, Arthur and Fergus, Rob},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {5842--5851},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/zhang18k/zhang18k.pdf},
  url = 	 {http://proceedings.mlr.press/v80/zhang18k.html},
  abstract = 	 {The tasks that an agent will need to solve often are not known during training. However, if the agent knows which properties of the environment are important then, after learning how its actions affect those properties, it may be able to use this knowledge to solve complex tasks without training specifically for them. Towards this end, we consider a setup in which an environment is augmented with a set of user defined attributes that parameterize the features of interest. We propose a method that learns a policy for transitioning between “nearby” sets of attributes, and maintains a graph of possible transitions. Given a task at test time that can be expressed in terms of a target set of attributes, and a current state, our model infers the attributes of the current state and searches over paths through attribute space to get a high level plan, and then uses its low level policy to execute the plan. We show in 3D block stacking, grid-world games, and StarCraft that our model is able to generalize to longer, more complex tasks at test time by composing simpler learned policies.}
}

@phdthesis{walsh2010efficient,
  title={Efficient learning of relational models for sequential decision making},
  author={Walsh, Thomas J},
  year={2010},
  school={Rutgers University-Graduate School-New Brunswick}
}

@Inbook{vanotterlo2012relational,
author="van Otterlo, Martijn",
editor="Wiering, Marco
and van Otterlo, Martijn",
title="Solving Relational and First-Order Logical Markov Decision Processes: A Survey",
bookTitle="Reinforcement Learning: State-of-the-Art",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="253--292",
abstract="In this chapter we survey representations and techniques for Markov decision processes, reinforcement learning, and dynamic programming in worlds explicitly modeled in terms of objects and relations. Such relational worlds can be found everywhere in planning domains, games, real-world indoor scenes and many more. Relational representations allow for expressive and natural datastructures that capture the objects and relations in an explicit way, enabling generalization over objects and relations, but also over similar problems which differ in the number of objects. The field was recently surveyed completely in (van Otterlo, 2009b), and here we describe a large portion of the main approaches. We discuss model-free -- both value-based and policy-based -- and model-based dynamic programming techniques. Several other aspects will be covered, such as models and hierarchies, and we end with several recent efforts and future directions.",
isbn="978-3-642-27645-3",
doi="10.1007/978-3-642-27645-3_8",
url="https://doi.org/10.1007/978-3-642-27645-3_8"
}

@inproceedings{topin2015portable,
  title={Portable Option Discovery for Automated Learning Transfer in Object-Oriented {M}arkov Decision Processes},
  author={Topin, Nicholay and Haltmeyer, Nicholas and Squire, Shawn and Winder, John and desJardins, Marie and MacGlashan, James},
  booktitle=ijcai,
  year={2015}
}

@article{franklin2018compositional,
  title={Compositional clustering in task structure learning},
  author={Franklin, Nicholas T and Frank, Michael J},
  journal={PLoS computational biology},
  volume={14},
  number={4},
  pages={e1006116},
  year={2018},
  publisher={Public Library of Science}
}

% Learning (from pixels?)
@inproceedings{zhu2018object,
  title={Object-oriented dynamics predictor},
  author={Zhu, Guangxiang and Huang, Zhiao and Zhang, Chongjie},
  booktitle=neurips,
  pages={9826--9837},
  year={2018}
}

% More structure/composition speeds up, MCTS outperforms other RL
@InProceedings{bapst2019structured,
  title = 	 {Structured agents for physical construction},
  author =       {Bapst, Victor and Sanchez-Gonzalez, Alvaro and Doersch, Carl and Stachenfeld, Kimberly and Kohli, Pushmeet and Battaglia, Peter and Hamrick, Jessica},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {464--474},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/bapst19a/bapst19a.pdf},
  url = 	 {
http://proceedings.mlr.press/v97/bapst19a.html
},
  abstract = 	 {Physical construction—the ability to compose objects, subject to physical dynamics, to serve some function—is fundamental to human intelligence. We introduce a suite of challenging physical construction tasks inspired by how children play with blocks, such as matching a target configuration, stacking blocks to connect objects together, and creating shelter-like structures over target objects. We examine how a range of deep reinforcement learning agents fare on these challenges, and introduce several new approaches which provide superior performance. Our results show that agents which use structured representations (e.g., objects and scene graphs) and structured policies (e.g., object-centric actions) outperform those which use less structured representations, and generalize better beyond their training when asked to reason about larger scenes. Model-based agents which use Monte-Carlo Tree Search also outperform strictly model-free agents in our most challenging construction problems. We conclude that approaches which combine structured representations and reasoning with powerful learning are a key path toward agents that possess rich intuitive physics, scene understanding, and planning.}
}


@INPROCEEDINGS{woof2018learning,
  author={Woof, William and Chen, Ke},
  booktitle={2018 IEEE Conference on Computational Intelligence and Games (CIG)}, 
  title={Learning to Play General Video-Games via an Object Embedding Network}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/CIG.2018.8490438}}


@inproceedings{braylan2016object,
  title={Object-model transfer in the general video game domain},
  author={Braylan, Alexander and Miikkulainen, Risto},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={12},
  number={1},
  year={2016}
}

% learning, MCTS outperforms
@article{keramati2018fast,
  title={Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning},
  author={Keramati, Ramtin and Whang, Jay and Cho, Patrick and Brunskill, Emma},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@article{van2019perspective,
  title={A perspective on objects and systematic generalization in model-based rl},
  author={van Steenkiste, Sjoerd and Greff, Klaus and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1906.01035},
  year={2019}
}

% able to build more complicated block towers than in training
@inproceedings{janner2019reasoning,
  title={Reasoning about physical interactions with object-oriented prediction and planning},
  author={Janner, Michael and Levine, Sergey and Freeman, William T and Tenenbaum, Joshua B and Finn, Chelsea and Wu, Jiajun},
  year={2019},
  organization={International Conference on Learning Representations}
}

% mentions interpretability
@inproceedings{crawford2019spatially,
  title={Spatially invariant unsupervised object detection with convolutional neural networks},
  author={Crawford, Eric and Pineau, Joelle},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3412--3420},
  year={2019}
}

% learning
@article{goel2018unsupervised,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Goel, Vikash and Weng, Jameson and Poupart, Pascal},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={5683--5694},
  year={2018}
}

% learning to do complicated things with objects
@inproceedings{baker2019emergent,
  title={Emergent Tool Use From Multi-Agent Autocurricula},
  author={Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{zambaldi2018deep,
title={Deep reinforcement learning with relational inductive biases},
author={Vinicius Zambaldi and David Raposo and Adam Santoro and Victor Bapst and Yujia Li and Igor Babuschkin and Karl Tuyls and David Reichert and Timothy Lillicrap and Edward Lockhart and Murray Shanahan and Victoria Langston and Razvan Pascanu and Matthew Botvinick and Oriol Vinyals and Peter Battaglia},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HkxaFoC9KQ},
}

@inproceedings{dubey2018investigating,
  title={Investigating Human Priors for Playing Video Games},
  author={Dubey, Rachit and Agrawal, Pulkit and Pathak, Deepak and Griffiths, Tom and Efros, Alexei},
  booktitle={International Conference on Machine Learning},
  pages={1349--1357},
  year={2018},
  organization={PMLR}
}

@InProceedings{scholz2014physics,
  title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
  author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
  booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
  pages = 	 {1089--1097},
  year = 	 {2014},
  editor = 	 {Eric P. Xing and Tony Jebara},
  volume = 	 {32},
  number =       {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Bejing, China},
  month = 	 {22--24 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v32/scholz14.pdf},
  url = 	 {http://proceedings.mlr.press/v32/scholz14.html},
  abstract = 	 {One of the key challenges in using reinforcement learning in robotics is the need for models that capture natural world structure. There are, methods that formalize multi-object dynamics using relational representations, but these methods are not sufficiently compact for  real-world robotics. We present a physics-based approach that exploits modern simulation tools to efficiently parameterize physical dynamics.  Our results show that this representation can result in much faster learning, by virtue of its strong but appropriate inductive bias in  physical environments.}
}

% end object oriented

@article{kerry2017gauging,
    title = {Gauging Investment in Self-Driving Cars},
    author = {Kerry, Cameron F. and Karsten, Jack},
    journal = {Brookings},
    year = {2017},
    date = {2017-10-16},
    url = {https://www.brookings.edu/research/gauging-investment-in-self-driving-cars/}
}

@book{lavalle2006planning,
  title={Planning algorithms},
  author={LaValle, Steven M},
  year={2006},
  publisher={Cambridge university press}
}

@inproceedings{zolfaghari2018eco,
  title={Eco: Efficient convolutional network for online video understanding},
  author={Zolfaghari, Mohammadreza and Singh, Kamaljeet and Brox, Thomas},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={695--712},
  year={2018}
}

@inproceedings{wu2017squeezedet,
  title={Squeezedet: Unified, small, low power fully convolutional neural networks for real-time object detection for autonomous driving},
  author={Wu, Bichen and Iandola, Forrest and Jin, Peter H and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={129--137},
  year={2017}
}

@inproceedings{doucett2000rao,
    author = {Doucett, Arnaud and Freitast, Nando De and Russent, Stuart},
    title = {{Rao-Blackwellised Particle Filtering for Dynamic Bayesian Networks}},
    booktitle = uai,
    year = {2000}
}

@article{karkus2019differentiable,
  title={Differentiable algorithm networks for composable robot learning},
  author={Karkus, Peter and Ma, Xiao and Hsu, David and Kaelbling, Leslie Pack and Lee, Wee Sun and Lozano-P{\'e}rez, Tom{\'a}s},
  journal={arXiv preprint arXiv:1905.11602},
  year={2019}
}

@inproceedings{bojarski2016end,
  title={End to End Learning for Self-Driving Cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol},
  booktitle=cvpr,
  year={2016}
}


@book{thrun2005probabilistic,
  title={Probabilistic Robotics},
  author={Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
  year={2005},
  publisher={The MIT Press}
}

@INPROCEEDINGS{jonschkowski2018differentiable, 
    AUTHOR    = {Rico Jonschkowski AND Divyam Rastogi AND Oliver Brock}, 
    TITLE     = {Differentiable Particle Filters: End-to-End Learning with Algorithmic Priors}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2018}, 
    ADDRESS   = {Pittsburgh, Pennsylvania}, 
    MONTH     = {June}, 
    DOI       = {10.15607/RSS.2018.XIV.001} 
} 

@inproceedings{bansal2017hamilton,
  title={Hamilton-Jacobi reachability: A brief overview and recent advances},
  author={Bansal, Somil and Chen, Mo and Herbert, Sylvia and Tomlin, Claire J},
  booktitle={2017 IEEE 56th Annual Conference on Decision and Control (CDC)},
  pages={2242--2253},
  year={2017},
  organization={IEEE}
}

@inproceedings{alshiekh2018safe,
  title={Safe reinforcement learning via shielding},
  author={Alshiekh, Mohammed and Bloem, Roderick and Ehlers, R{\"u}diger and K{\"o}nighofer, Bettina and Niekum, Scott and Topcu, Ufuk},
  booktitle=aaai,
  volume={32},
  number={1},
  year={2018}
}


@InProceedings{hafner2019planet,
  title = 	 {Learning Latent Dynamics for Planning from Pixels},
  author =       {Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2555--2565},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/hafner19a/hafner19a.pdf},
  url = 	 {
http://proceedings.mlr.press/v97/hafner19a.html
},
  abstract = 	 {Planning has been very successful for control tasks with known environment dynamics. To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the world. However, learning dynamics models that are accurate enough for planning has been a long-standing challenge, especially in image-based domains. We propose the Deep Planning Network (PlaNet), a purely model-based agent that learns the environment dynamics from images and chooses actions through fast online planning in latent space. To achieve high performance, the dynamics model must accurately predict the rewards ahead for multiple time steps. We approach this using a latent dynamics model with both deterministic and stochastic transition components. Moreover, we propose a multi-step variational inference objective that we name latent overshooting. Using only pixel observations, our agent solves continuous control tasks with contact dynamics, partial observability, and sparse rewards, which exceed the difficulty of tasks that were previously solved by planning with learned models. PlaNet uses substantially fewer episodes and reaches final performance close to and sometimes higher than strong model-free algorithms.}
}

@InProceedings{gautam2021self,
author="Gautam, Alvika
and Crandall, Jacob W.
and Goodrich, Michael A.",
editor="Zallio, Matteo",
title="Self-assessment of Proficiency of Intelligent Systems: Challenges and Opportunities",
booktitle="Advances in Human Factors in Robots, Drones and Unmanned Systems",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="108--113",
abstract="Autonomous systems, although capable of performing complicated tasks much faster than humans, are brittle due to uncertainties encountered in most real-time applications. People supervising these systems often rely on information relayed by the system to make any decisions, which places a burden on the system to self-assess its proficiency and communicate the relevant information.",
isbn="978-3-030-51758-8"
}

@article{julian2019verifying,
  title={Verifying aircraft collision avoidance neural networks through linear approximations of safe regions},
  author={Julian, Kyle D and Sharma, Shivam and Jeannin, Jean-Baptiste and Kochenderfer, Mykel J},
  journal={arXiv preprint arXiv:1903.00762},
  year={2019}
}

@ARTICLE{kschischang2001factor,
  author={Kschischang, F.R. and Frey, B.J. and Loeliger, H.-A.},
  journal={IEEE Transactions on Information Theory}, 
  title={Factor graphs and the sum-product algorithm}, 
  year={2001},
  volume={47},
  number={2},
  pages={498-519},
  doi={10.1109/18.910572}}

% BEGIN OOD

@article{ren2019likelihood,
  title={Likelihood Ratios for Out-of-Distribution Detection},
  author={Ren, Jie and Liu, Peter J and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and Depristo, Mark and Dillon, Joshua and Lakshminarayanan, Balaji},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={14707--14718},
  year={2019}
}

@inproceedings{moller2021out,
  title={Out-of-distribution Detection and Generation using Soft Brownian Offset Sampling and Autoencoders},
  author={Moller, Felix and Botache, Diego and Huseljic, Denis and Heidecker, Florian and Bieshaar, Maarten and Sick, Bernhard},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={46--55},
  year={2021}
}

@misc{fort2021exploring,
      title={Exploring the Limits of Out-of-Distribution Detection}, 
      author={Stanislav Fort and Jie Ren and Balaji Lakshminarayanan},
      year={2021},
      eprint={2106.03004},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{liang2018enhancing,
  title={Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks},
  author={Liang, Shiyu and Li, Yixuan and Srikant, R},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{lee2018simple,
  title={A simple unified framework for detecting out-of-distribution samples and adversarial attacks},
  author={Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{choi2018waic,
  title={{WAIC}, but why? generative ensembles for robust anomaly detection},
  author={Choi, Hyunsun and Jang, Eric and Alemi, Alexander A},
  journal={arXiv preprint arXiv:1810.01392},
  year={2018}
}

@article{lakshminarayanan2017simple,
  title={Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{bock2020ind,
  title={The {IND} Dataset: A Drone Dataset Of Naturalistic Road User Trajectories at {G}erman Intersections},
  author={Bock, Julian and Krajewski, Robert and Moers, Tobias and Runde, Steffen and Vater, Lennart and Eckstein, Lutz},
  booktitle={2020 IEEE Intelligent Vehicles Symposium (IV)},
  pages={1929--1934},
  year={2020},
  organization={IEEE}
}

@article{armeni2017joint,
  title={Joint 2d-3d-semantic data for indoor scene understanding},
  author={Armeni, Iro and Sax, Sasha and Zamir, Amir R and Savarese, Silvio},
  journal={arXiv preprint arXiv:1702.01105},
  year={2017}
}

@inproceedings{pineau2003point,
  title={Point-based value iteration: An anytime algorithm for {POMDP}s},
  author={Pineau, Joelle and Gordon, Geoff and Thrun, Sebastian},
  booktitle={IJCAI},
  volume={3},
  pages={1025--1032},
  year={2003},
  organization={Citeseer}
}

@article{spaan2005perseus,
  title={Perseus: Randomized point-based value iteration for {POMDP}s},
  author={Spaan, Matthijs TJ and Vlassis, Nikos},
  journal={Journal of artificial intelligence research},
  volume={24},
  pages={195--220},
  year={2005}
}

@incollection{bai2010monte,
  title={{M}onte {C}arlo value iteration for continuous-state {POMDP}s},
  author={Bai, Haoyu and Hsu, David and Lee, Wee Sun and Ngo, Vien A},
  booktitle={Algorithmic foundations of robotics IX},
  pages={175--191},
  year={2010},
  publisher={Springer}
}

@article{barto1995learning,
  title={Learning to act using real-time dynamic programming},
  author={Barto, Andrew G and Bradtke, Steven J and Singh, Satinder P},
  journal={Artificial intelligence},
  volume={72},
  number={1-2},
  pages={81--138},
  year={1995},
  publisher={Elsevier}
}

@article{zhao2020meld,
  title={MELD: Meta-Reinforcement Learning from Images via Latent State Models},
  author={Zhao, Tony Z and Nagabandi, Anusha and Rakelly, Kate and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.13957},
  year={2020}
}

@article{schrittwieser2021online,
  title={Online and offline reinforcement learning by planning with a learned model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:2104.06294},
  year={2021}
}

@inproceedings{schmeckpeper2020learning,
  title={Learning predictive models from observation and interaction},
  author={Schmeckpeper, Karl and Xie, Annie and Rybkin, Oleh and Tian, Stephen and Daniilidis, Kostas and Levine, Sergey and Finn, Chelsea},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XX 16},
  pages={708--725},
  year={2020},
  organization={Springer}
}

@article{chen2021learning,
  title={Learning Generalizable Robotic Reward Functions from" In-The-Wild" Human Videos},
  author={Chen, Annie S and Nair, Suraj and Finn, Chelsea},
  journal={arXiv preprint arXiv:2103.16817},
  year={2021}
}

@article{chevalier2019robo,
  title={Robo-PlaNet: Learning to Poke in a Day},
  author={Chevalier-Boisvert, Maxime and Alain, Guillaume and Golemo, Florian and Nowrouzezahrai, Derek},
  journal={arXiv preprint arXiv:1911.03594},
  year={2019}
}

@inproceedings{haarnoja2018composable,
  title={Composable deep reinforcement learning for robotic manipulation},
  author={Haarnoja, Tuomas and Pong, Vitchyr and Zhou, Aurick and Dalal, Murtaza and Abbeel, Pieter and Levine, Sergey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={6244--6251},
  year={2018},
  organization={IEEE}
}

@article{humplik2019meta,
  title={Meta reinforcement learning as task inference},
  author={Humplik, Jan and Galashov, Alexandre and Hasenclever, Leonard and Ortega, Pedro A and Teh, Yee Whye and Heess, Nicolas},
  journal={arXiv preprint arXiv:1905.06424},
  year={2019}
}

@inproceedings{julian2020validation,
  title={Validation of image-based neural network controllers through adaptive stress testing},
  author={Julian, Kyle D and Lee, Ritchie and Kochenderfer, Mykel J},
  booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@inproceedings{vachovsky2016toward,
  title={Toward more gender diversity in {CS} through an artificial intelligence summer program for high school girls},
  author={Vachovsky, Marie E and Wu, Grace and Chaturapruek, Sorathan and Russakovsky, Olga and Sommer, Richard and Fei-Fei, Li},
  booktitle={Proceedings of the 47th ACM Technical Symposium on Computing Science Education},
  pages={303--308},
  year={2016}
}

@article{stathoulopoulos2019gender,
  title={Gender diversity in {AI} research},
  author={Stathoulopoulos, Konstantinos and Mateos-Garcia, Juan C.},
  journal={Available at SSRN 3428240},
  year={2019}
}

@misc{khan2020state,
    author={Beethika Khan and Carol Robbins and Abigail Okrent},
    title={The State of {US} Science and Engineering},
    year={2020},
    institution={National Science Foundation and National Science Board}
}

@article{kilgore2007considering,
	title = {Considering Context: A Study of First-Year Engineering Students},
	journal = {Journal of Engineering Education},
	author = {Deborah Kilgore and Cynthia J. Atman and Ken Yasuhara and Theresa J. Barker and Andrew Morozov},
	volume = { 96},
	number = {4},
	year = {2007},
	pages = {321-334},
} 

@book{committee2008changing,
	author="{Committee on Public Understanding of Engineering Messages, National Academy of Engineering}",
	year={2008},
	title={Changing the Conversation: Messages for Improving Public Understanding of Engineering},
	publisher={National Academies Press},
	address={Washington, DC},
}

@article{pettigrew2017public,
  title={Why public health should embrace the autonomous car},
  author={Pettigrew, Simone},
  journal={Australian and New Zealand journal of public health},
  volume={41},
  pages={1--3},
  year={2017},
  publisher={Wiley-Blackwell Publishing Asia}
}

@article{truszkowski2006autonomous,
  title={Autonomous and autonomic systems: A paradigm for future space exploration missions},
  author={Truszkowski, Walter F and Hinchey, Michael G and Rash, James L and Rouff, Christopher A},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={36},
  number={3},
  pages={279--291},
  year={2006},
  publisher={IEEE}
}

@article{frew2020field,
  title={Field observation of tornadic supercells by multiple autonomous fixed-wing unmanned aircraft},
  author={Frew, Eric W and Argrow, Brian and Borenstein, Steve and Swenson, Sara and Hirst, C Alexander and Havenga, Henno and Houston, Adam},
  journal={Journal of Field Robotics},
  volume={37},
  number={6},
  pages={1077--1093},
  year={2020},
  publisher={Wiley Online Library}
}

@inproceedings{sadigh2016information,
  title={Information gathering actions over human internal state},
  author={Sadigh, Dorsa and Sastry, S Shankar and Seshia, Sanjit A and Dragan, Anca},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={66--73},
  year={2016},
  organization={IEEE}
}

@article{huang2021visual,
  title={Visual Foresight Tree for Object Retrieval from Clutter with Nonprehensile Rearrangement},
  author={Huang, Baichuan and Han, Shuai D and Yu, Jingjin and Boularias, Abdeslam},
  journal={arXiv preprint arXiv:2105.02857},
  year={2021}
}

@inproceedings{abadi2016tensorflow,
  title={TensorFlow: A System for Large-scale Machine Learning},
  author={Abadi, Mart{\'i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael  and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zhen},
  booktitle={12th {USENIX} symposium on operating systems design and implementation {OSDI} 16)},
  pages={265--283},
  year={2016}
}

@inproceedings{corso2019adaptive,
  title={Adaptive stress testing with reward augmentation for autonomous vehicle validation},
  author={Corso, Anthony and Du, Peter and Driggs-Campbell, Katherine and Kochenderfer, Mykel J},
  booktitle={2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
  pages={163--168},
  year={2019},
  organization={IEEE}
}

@inproceedings{dosovitskiy2017carla,
  title={{CARLA}: An open urban driving simulator},
  author={Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
  booktitle={Conference on robot learning},
  pages={1--16},
  year={2017},
  organization={PMLR}
}

@misc{nhtsa2019fatality,
    url={https://www-fars.nhtsa.dot.gov/Main/index.aspx},
    author={{National Highway Traffic Safety Administration}},
    title={Fatality Analysis Reporting System ({FARS})},
    year=2019
}

@misc{cto2021modernization,
    author={{Office of the Under Secretary of Defense,
Research and Engineering}},
    url={https://www.cto.mil/modernization-priorities/},
    title={Modernization Priorities},
    date=2021
}

@article{wood2017autonomous,
title = {An autonomous control framework for advanced reactors},
journal = {Nuclear Engineering and Technology},
volume = {49},
number = {5},
pages = {896-904},
year = {2017},
issn = {1738-5733},
doi = {https://doi.org/10.1016/j.net.2017.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1738573317304096},
author = {Richard T. Wood and Belle R. Upadhyaya and Dan C. Floyd},
keywords = {Autonomous Control, Instrumentation and Control System, Small Modular Reactor},
}

@article{rossi2018routing,
  title={Routing autonomous vehicles in congested transportation networks: Structural properties and coordination algorithms},
  author={Rossi, Federico and Zhang, Rick and Hindy, Yousef and Pavone, Marco},
  journal={Autonomous Robots},
  volume={42},
  number={7},
  pages={1427--1442},
  year={2018},
  publisher={Springer}
}

@INPROCEEDINGS{tsao2018stochastic,
  author={Tsao, Matthew and Iglesias, Ramon and Pavone, Marco},
  booktitle={2018 21st International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={Stochastic Model Predictive Control for Autonomous Mobility on Demand}, 
  year={2018},
  volume={},
  number={},
  pages={3941-3948},
  doi={10.1109/ITSC.2018.8569459}
}


@article{bigelow2019disabled,
    title={Disabled fail-safe at issue in Uber crash},
    author={Bigelow, Pete},
    journal={Automotive News},
    year={2019},
    date={2019-11-18},
    url={https://www.autonews.com/mobility-report/disabled-fail-safe-issue-uber-crash}
}

@inproceedings{singh2019end,
  title={End-To-End Robotic Reinforcement Learning without Reward Engineering.},
  author={Singh, Avi and Yang, Larry and Finn, Chelsea and Levine, Sergey},
  booktitle=rss,
  year={2019}
}

@article{chiang2019learning,
  title={Learning navigation behaviors end-to-end with autorl},
  author={Chiang, Hao-Tien Lewis and Faust, Aleksandra and Fiser, Marek and Francis, Anthony},
  journal={IEEE Robotics and Automation Letters},
  volume={4},
  number={2},
  pages={2007--2014},
  year={2019},
  publisher={IEEE}
}

@misc{grant2014cvx,
  title={{CVX}: Matlab software for disciplined convex programming, version 2.1},
  author={Grant, Michael and Boyd, Stephen},
  year={2014}
}

@misc{sunberg2021pomdps,
    title={POMDPs.jl and Interactive Assignments in Julia},
    author={Sunberg, Zachary},
    author+an={1=zach},
    year=2021,
    note={JuliaCon presentation},
    booktitle={JuliaCon}
}

@inproceedings{quigley2009ros,
  title={{ROS}: An Open-source Robot Operating System},
  author={Quigley, Morgan and Conley, Ken and Gerkey, Brian and Faust, Josh and Foote, Tully and Leibs, Jeremy and Berger, Eric and Wheeler, Rob and Ng, Andrew Y.},
  booktitle={ICRA workshop on open source software},
  volume={3},
  number={3.2},
  pages={5},
  year={2009},
  organization={Kobe, Japan}
}

@inproceedings{wang2020dualsmc,
  title     = {{DualSMC}: Tunneling Differentiable Filtering and Planning under Continuous {POMDP}s},
  author    = {Wang, Yunbo and Liu, Bo and Wu, Jiajun and Zhu, Yuke and Du, Simon S. and Fei-Fei, Li and Tenenbaum, Joshua B.},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  pages     = {4190--4198},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/579},
  url       = {https://doi.org/10.24963/ijcai.2020/579},
}

@article{agha2014firm,
  title={{FIRM}: Sampling-based feedback motion-planning under motion uncertainty and imperfect measurements},
  author={Agha-Mohammadi, Ali-Akbar and Chakravorty, Suman and Amato, Nancy M},
  journal=ijrr,
  volume={33},
  number={2},
  pages={268--304},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{bry2011rapidly,
  title={Rapidly-exploring random belief trees for motion planning under uncertainty},
  author={Bry, Adam and Roy, Nicholas},
  booktitle=icra,
  pages={723--730},
  year={2011},
  organization={IEEE}
}

@book{russel2021artificial,
  author = {Russell, Stuart and Norvig, Peter},
  edition = 4,
  publisher = {Prentice Hall},
  title = {Artificial Intelligence: A Modern Approach},
  year = 2021
}

@article{memarzadeh2018adaptive,
  title={Adaptive Management of Ecological Systems under Partial Observability},
  author={Memarzadeh, Milad and Boettiger, Carl},
  journal={Biological Conservation},
  volume={224},
  pages={9--15},
  year={2018},
  publisher={Elsevier}
}

@article{wu2021adaptive,
  title={Adaptive Online Packing-guided Search for {POMDP}s},
  author={Wu, Chenyang and Yang, Guoyu and Zhang, Zongzhang and Yu, Yang and Li, Dong and Liu, Wulong and Hao, Jianye},
  journal=neurips,
  volume={34},
  year={2021}
}

@article{smallwood1973optimal,
  title={The optimal control of partially observable {M}arkov processes over a finite horizon},
  author={Smallwood, Richard D and Sondik, Edward J},
  journal={Operations research},
  volume={21},
  number={5},
  pages={1071--1088},
  year={1973},
  publisher={INFORMS}
}

@article{shani2013survey,
  title={A survey of point-based {POMDP} solvers},
  author={Shani, Guy and Pineau, Joelle and Kaplow, Robert},
  journal=aamas,
  volume={27},
  number={1},
  pages={1--51},
  year={2013},
  publisher={Springer}
}

@book{isaacs1965differential,
  title={Differential games: a mathematical theory with applications to warfare and pursuit, control and optimization},
  author={Isaacs, Rufus},
  year={1965},
  publisher={John Wiley and Sons}
}

@inproceedings{peters2022learning,
  title={Learning Mixed Strategies in Trajectory Games},
  author={Peters, Lasse and Laine, Forrest and Fridovich-Keil, David},
  year={2022},
  booktitle=rss
}

@inproceedings{dyro2021particle,
  title={Particle {MPC} for Uncertain and Learning-Based Control},
  author={Dyro, Robert and Harrison, James and Sharma, Apoorva and Pavone, Marco},
  booktitle=iros,
  pages={7127--7134},
  year={2021},
  organization={IEEE}
}

@article{houston2012collaborative,
  title={The collaborative {C}olorado--{N}ebraska unmanned aircraft system experiment},
  author={Houston, Adam L. and Argrow, Brian and Elston, Jack and Lahowetz, Jamie and Frew, Eric W. and Kennedy, Patrick C.},
  journal={Bulletin of the American Meteorological Society},
  volume={93},
  number={1},
  pages={39--54},
  year={2012},
  publisher={American Meteorological Society}
}

@inproceedings{bresina2002planning,
  title={Planning under Continuous Time and Resource Uncertainty: a challenge for {AI}},
  author={Bresina, J. and Dearden, Richard and Meuleau, N. and Ramakrishnan, S. and Smith, D. and Washington, R. and Darwiche, A. and Friedman, N.},
  booktitle=uai,
  year={2002}
}

@article{daskalakis2009complexity,
  title={The Complexity of Computing a Nash Equilibrium},
  author={Daskalakis, Constantinos and Goldberg, Paul W. and Papadimitriou, Christos H.},
  journal={{SIAM} Journal on Computing},
  volume={39},
  number={1},
  pages={195--259},
  year={2009},
  publisher={{SIAM}}
}

@article{koller1992complexity,
  title={The Complexity of Two-person Zero-sum Games in Extensive Form},
  author={Koller, Daphne and Megiddo, Nimrod},
  journal={Games and Economic Behavior},
  volume={4},
  number={4},
  pages={528--552},
  year={1992},
  publisher={Elsevier}
}

@article{schmid2021player,
  title={Player of games},
  author={Schmid, Martin and Moravcik, Matej and Burch, Neil and Kadlec, Rudolf and Davidson, Josh and Waugh, Kevin and Bard, Nolan and Timbers, Finbarr and Lanctot, Marc and Holland, Zach and others},
  journal={arXiv preprint arXiv:2112.03178},
  year={2021}
}

@techreport{karako2022complex,
    title={Complex Air Defense: Countering the Hypersonic Missile Threat},
    author={Tom Karako and Masao Dahlgren},
    year=2022,
    institution={Center for Strategic and International Studies (CSIS)},
}

@article{auer2002finite,
  title={Finite-time Analysis of the Multiarmed Bandit Problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine Learning},
  volume={47},
  number={2},
  pages={235--256},
  year={2002},
  publisher={Springer}
}

@article{perolat2022mastering,
  title={Mastering the game of Stratego with model-free multiagent reinforcement learning},
  author={Julien Perolat  and Bart De Vylder  and Daniel Hennes  and Eugene Tarassov  and Florian Strub  and Vincent de Boer  and Paul Muller  and Jerome T. Connor  and Neil Burch  and Thomas Anthony  and Stephen McAleer  and Romuald Elie  and Sarah H. Cen  and Zhe Wang  and Audrunas Gruslys  and Aleksandra Malysheva  and Mina Khan  and Sherjil Ozair  and Finbarr Timbers  and Toby Pohlen  and Tom Eccles  and Mark Rowland  and Marc Lanctot  and Jean-Baptiste Lespiau  and Bilal Piot  and Shayegan Omidshafiei  and Edward Lockhart  and Laurent Sifre  and Nathalie Beauguerlange  and Remi Munos  and David Silver  and Satinder Singh  and Demis Hassabis  and Karl Tuyls},
  journal={Science},
  volume={378},
  number={6623},
  pages={990--996},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{zhang2019online,
  title={Online Planning for Decentralized Stochastic Control with Partial History Sharing},
  author={Zhang, Kaiqing and Miehling, Erik and Ba{\c{s}}ar, Tamer},
  booktitle=acc,
  pages={3544--3550},
  year={2019},
  organization={IEEE}
}

@inproceedings{amato2015scalable,
  title={Scalable Planning and Learning for Multiagent {POMDP}s},
  author={Amato, Christopher and Oliehoek, Frans},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={29},
  number={1},
  year={2015}
}

@article{czechowski2020decentralized,
  title={Decentralized {MCTS} via Learned Teammate Models},
  author={Czechowski, Aleksander and Oliehoek, Frans A},
  journal={arXiv preprint arXiv:2003.08727},
  year={2020}
}

@article{asik2023decoupled,
  title={Decoupled {M}onte {C}arlo Tree Search for Cooperative Multi-Agent Planning},
  author={Asik, Okan and Aydemir, Fatma Ba{\c{s}}ak and Ak{\i}n, H{\"u}seyin Levent},
  journal={Applied Sciences},
  volume={13},
  number={3},
  year={2023},
  publisher={MDPI}
}

@book{albrecht2023marl,
  author = {Stefano V. Albrecht and Filippos Christianos and Lukas Sch\"afer},
  title = {Multi-Agent Reinforcement Learning: Foundations and Modern Approaches},
  publisher = {MIT Press},
  year = {2023},
  url = {https://www.marl-book.com}
}

@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of reinforcement learning and control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}

@article{durfee2013multiagent,
  title={Multiagent planning, control, and execution},
  author={Durfee, Edmund and Zilberstein, Shlomo},
  journal={Multiagent systems},
  volume={11},
  pages={485--545},
  year={2013},
  publisher={MIT Press Cambridge}
}

@inproceedings{bai2015intention,
  title={Intention-aware online {POMDP} planning for autonomous driving in a crowd},
  author={Bai, Haoyu and Cai, Shaojun and Ye, Nan and Hsu, David and Lee, Wee Sun},
  booktitle=icra,
  pages={454--460},
  year={2015},
  organization={IEEE}
}

@article{luo2018porca,
  title={{PORCA}: Modeling and planning for autonomous driving among many pedestrians},
  author={Luo, Yuanfu and Cai, Panpan and Bera, Aniket and Hsu, David and Lee, Wee Sun and Manocha, Dinesh},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={4},
  pages={3418--3425},
  year={2018},
  publisher={IEEE}
}

@book{oliehoek2016concise,
  title={A Concise Introduction to Decentralized {POMDP}s},
  author={Oliehoek, Frans A. and Amato, Christopher},
  year={2016},
  publisher={Springer}
}

@article{marden2009cooperative,
  title={Cooperative control and potential games},
  author={Marden, Jason R and Arslan, G{\"u}rdal and Shamma, Jeff S},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume={39},
  number={6},
  pages={1393--1407},
  year={2009},
  publisher={IEEE}
}

@inproceedings{nair2003taming,
  title={Taming decentralized POMDPs: Towards efficient policy computation for multiagent settings},
  author={Nair, Ranjit and Tambe, Milind and Yokoo, Makoto and Pynadath, David and Marsella, Stacy},
  booktitle=ijcai,
  volume={3},
  pages={705--711},
  year={2003}
}

@inproceedings{bernstein2005bounded,
  title={Bounded policy iteration for decentralized POMDPs},
  author={Bernstein, Daniel S and Hansen, Eric A and Zilberstein, Shlomo},
  booktitle=ijcai,
  pages={52--57},
  year={2005}
}

@book{nisan2007algorithmic,
  title={Algorithmic Game Theory},
  author={Nisan, Noam and Roughgarden, Tim and Tardos, Eva and Vazirani, Vijay V},
  year=2007,
  publisher={Cambridge University Press}
}

@inproceedings{kearns2000fast,
  title={Fast planning in stochastic games},
  author={Kearns, Michael and Mansour, Yishay and Singh, Satinder},
  booktitle=uai,
  pages={309--316},
  year={2000}
}

@article{gibbons1997introduction,
  title={An introduction to applicable game theory},
  author={Gibbons, Robert},
  journal={Journal of Economic Perspectives},
  volume={11},
  number={1},
  pages={127--149},
  year={1997},
  publisher={American Economic Association}
}

@book{camerer2011behavioral,
  title={Behavioral game theory: Experiments in strategic interaction},
  author={Camerer, Colin F.},
  year={2011},
  publisher={Princeton University Press}
}

@article{doshi2009monte,
  title={{M}onte {C}arlo sampling methods for approximating interactive {POMDP}s},
  author={Doshi, Prashant and Gmytrasiewicz, Piotr J.},
  journal=jair,
  volume={34},
  pages={297--337},
  year={2009}
}

@inproceedings{gmytrasiewicz2004interactive,
  title={Interactive {POMDP}s: Properties and preliminary results},
  author={Gmytrasiewicz, Piotr J. and Doshi, Prashant},
  booktitle=aamas,
  volume={3},
  pages={1374--1375},
  year={2004}
}

@inproceedings{coates2004distributed,
  title={Distributed particle filters for sensor networks},
  author={Coates, Mark},
  booktitle={Proceedings of the 3rd international symposium on Information processing in sensor networks},
  pages={99--107},
  year={2004}
}

@inproceedings{herz2013ssa,
  title={{SSA} sensor tasking approach for improved orbit determination accuracies and more efficient use of ground assets},
  author={Herz, Alexander F and Stoner, Frank and Hall, Robert and Fisher, William},
  booktitle= amos,
  year={2013}
}

@inproceedings{lisy2015online,
  title={Online {M}onte {C}arlo Counterfactual Regret Minimization for Search in Imperfect Information Games.},
  author={Lisy, Viliam and Lanctot, Marc and Bowling, Michael H.},
  booktitle=aamas,
  pages={27--36},
  year={2015}
}

@article{cowling2012information,
  title={Information set {M}onte {C}arlo tree search},
  author={Cowling, Peter I. and Powley, Edward J. and Whitehouse, Daniel},
  journal={{IEEE} Transactions on Computational Intelligence and AI in Games},
  volume={4},
  number={2},
  pages={120--143},
  year={2012},
  publisher={IEEE}
}

@article{robinson1951iterative,
  title={An iterative method of solving a game},
  author={Robinson, Julia},
  journal={Annals of mathematics},
  pages={296--301},
  year={1951},
  publisher={JSTOR}
}

@article{fang2017paws,
  title={{PAWS}—A deployed game-theoretic application to combat poaching},
  author={Fang, Fei and Nguyen, Thanh H. and Pickles, Rob and Lam, Wai Y. and Clements, Gopalasamy R. and An, Bo and Singh, Amandeep and Schwedock, Brian C. and Tambe, Milin and Lemieux, Andrew},
  journal={AI Magazine},
  volume={38},
  number={1},
  pages={23--36},
  year={2017}
}

@inproceedings{badura2022system,
  title={System design and analysis for cislunar space domain awareness through distributed sensors},
  author={Badura, Gregory and Shimane, Yuri and Gregoire, Alaric and Patel, Rohan and Gilmartin, Matthew and Gangolli, Kunal and Visonneau, Lois and Tysor, Joshua and Manojkumar, S. and Humphrey, F. and Valenta, Chris and Reilly, Blair and Lourenco, Nelson and Hodkin, Jason and Sudol, Alicia and Borowitz, Mariel and Gunter, Brian and Christian, John and Koki Ho},
  booktitle={AAS/AIAA Astrodynamics Specialist Conference, Charlotte, NC},
  pages={1--20},
  year={2022}
}

@article{wang2023optimizing,
  title={Optimizing Carbon Storage Operations for Long-Term Safety},
  author={Wang, Yizheng and Zechner, Markus and Wen, Gege and Corso, Anthony Louis and Mern, John Michael and Kochenderfer, Mykel J. and Caers, Jef Karel},
  journal={arXiv preprint arXiv:2304.09352},
  year={2023}
}

@article{meta2022human,
  title={Human-level play in the game of Diplomacy by combining language models with strategic reasoning},
  author={Meta Fundamental AI Research Diplomacy Team (FAIR) and Anton Bakhtin  and Noam Brown  and Emily Dinan  and Gabriele Farina  and Colin Flaherty  and Daniel Fried  and Andrew Goff  and Jonathan Gray  and Hengyuan Hu  and Athul Paul Jacob  and Mojtaba Komeili  and Karthik Konath  and Minae Kwon  and Adam Lerer  and Mike Lewis  and Alexander H. Miller  and Sasha Mitts  and Adithya Renduchintala  and Stephen Roller  and Dirk Rowe  and Weiyan Shi  and Joe Spisak  and Alexander Wei  and David Wu  and Hugh Zhang  and Markus Zijlstra},
  journal={Science},
  volume={378},
  number={6624},
  pages={1067--1074},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{bakhtin2022mastering,
  title={Mastering the game of no-press Diplomacy via human-regularized reinforcement learning and planning},
  author={Bakhtin, Anton and Wu, David J. and Lerer, Adam and Gray, Jonathan and Jacob, Athul Paul and Farina, Gabriele and Miller, Alexander H. and Brown, Noam},
  journal={arXiv preprint arXiv:2210.05492},
  year={2022}
}

@inproceedings{kuefler2017imitating,
  title={Imitating driver behavior with generative adversarial networks},
  author={Kuefler, Alex and Morton, Jeremy and Wheeler, Tim and Kochenderfer, Mykel},
  booktitle={2017 IEEE Intelligent Vehicles Symposium (IV)},
  pages={204--211},
  year={2017},
  organization={IEEE}
}

@article{gindele2015learning,
  title={Learning driver behavior models from traffic observations for decision making and planning},
  author={Gindele, Tobias and Brechtel, Sebastian and Dillmann, Rudiger},
  journal={{IEEE} Intelligent Transportation Systems Magazine},
  volume={7},
  number={1},
  pages={69--79},
  year={2015},
  publisher={IEEE}
}

@article{li2022reducing,
  title={Reducing Collision Risk in Multi-Agent Path Planning: Application to Air traffic Management},
  author={Li, Sarah HQ and Mittal, Avi and Acikmese, Behcet},
  journal={arXiv preprint arXiv:2212.04122},
  year={2022}
}

@inproceedings{brechtel2014probabilistic,
  title={Probabilistic decision-making under uncertainty for autonomous driving using continuous POMDPs},
  author={Brechtel, Sebastian and Gindele, Tobias and Dillmann, R{\"u}diger},
  booktitle={17th international IEEE conference on intelligent transportation systems (ITSC)},
  pages={392--399},
  year={2014},
  organization={IEEE}
}

@inproceedings{fridovich2020efficient,
  title={Efficient iterative linear-quadratic approximations for nonlinear multi-player general-sum differential games},
  author={Fridovich-Keil, David and Ratner, Ellis and Peters, Lasse and Dragan, Anca D and Tomlin, Claire J},
  booktitle={2020 IEEE international conference on robotics and automation (ICRA)},
  pages={1475--1481},
  year={2020},
  organization={IEEE}
}

@article{wang2021game,
  title={Game-theoretic planning for self-driving cars in multivehicle competitive scenarios},
  author={Wang, Mingyu and Wang, Zijian and Talbot, John and Gerdes, J. Christian and Schwager, Mac},
  journal={{IEEE} Transactions on Robotics},
  volume={37},
  number={4},
  pages={1313--1325},
  year={2021},
  publisher={IEEE}
}

@article{subramanian2022approximate,
  title={Approximate information state for approximate planning and reinforcement learning in partially observed systems},
  author={Subramanian, Jayakumar and Sinha, Amit and Seraj, Raihan and Mahajan, Aditya},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={483--565},
  year={2022},
  publisher={JMLRORG}
}

@inproceedings{fischer2020information,
  title={Information particle filter tree: An online algorithm for pomdps with belief-based rewards on continuous domains},
  author={Fischer, Johannes and Tas, {\"O}mer Sahin},
  booktitle={International Conference on Machine Learning},
  pages={3177--3187},
  year={2020},
  organization={PMLR}
}

@article{choudhury2022dynamic,
  title={Dynamic multi-robot task allocation under uncertainty and temporal constraints},
  author={Choudhury, Shushman and Gupta, Jayesh K and Kochenderfer, Mykel J. and Sadigh, Dorsa and Bohg, Jeannette},
  journal={Autonomous Robots},
  volume={46},
  number={1},
  pages={231--247},
  year={2022},
  publisher={Springer}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{terry2021pettingzoo,
  title={Pettingzoo: Gym for multi-agent reinforcement learning},
  author={Terry, J and Black, Benjamin and Grammel, Nathaniel and Jayakumar, Mario  and Hari, Ananth  and Sullivan, Ryan and Santos, Luis S and Dieffendahl, Clemens and Horsch, Caroline and Perez-Vicente, Rodrigo and Williams, Niall  and Lokesh, Yashas  and Ravi , Praveen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15032--15043},
  year={2021}
}

@article{raymond1999cathedral,
  title={The cathedral and the bazaar},
  author={Raymond, Eric},
  journal={Knowledge, Technology \& Policy},
  volume={12},
  number={3},
  pages={23--49},
  year={1999},
  publisher={Springer}
}

@misc{procida2017what,
    title={What nobody tells you about documentation},
    author={Procida, Daniele},
    year=2017,
    note={PyCon Australia Presentation},
    url={https://www.youtube.com/watch?v=t4vKPhjcMZg}
}

@inproceedings{tourani2017code,
  title={Code of conduct in open source projects},
  author={Tourani, Parastou and Adams, Bram and Serebrenik, Alexander},
  booktitle={International conference on software analysis, evolution and reengineering (SANER)},
  pages={24--33},
  year={2017},
  organization={{IEEE}}
}

@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle=aaai,
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{khan2009minimal,
  title={Minimal sufficient explanations for factored markov decision processes},
  author={Khan, Omar and Poupart, Pascal and Black, James},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={19},
  pages={194--200},
  year={2009}
}

@article{moss2023betazero,
  title={BetaZero: Belief-State Planning for Long-Horizon {POMDP}s using Learned Approximations},
  author={Moss, Robert J and Corso, Anthony and Caers, Jef and Kochenderfer, Mykel J},
  journal={arXiv preprint arXiv:2306.00249},
  year={2023}
}

@book{osborne1994course,
  title={A course in game theory},
  author={Osborne, Martin J and Rubinstein, Ariel},
  year={1994},
  publisher={MIT press}
}

@inproceedings{gupta2017cooperative,
  title={Cooperative multi-agent control using deep reinforcement learning},
  author={Gupta, Jayesh K. and Egorov, Maxim and Kochenderfer, Mykel},
  booktitle=aamas,
  pages={66--83},
  year={2017},
  organization={Springer}
}

@article{gronauer2022multi,
  title={Multi-agent deep reinforcement learning: a survey},
  author={Gronauer, Sven and Diepold, Klaus},
  journal={Artificial Intelligence Review},
  pages={1--49},
  year={2022},
  publisher={Springer}
}

@inproceedings{jamgochian2023online,
  title={Online planning for constrained POMDPs with continuous spaces through dual ascent},
  author={Jamgochian, Arec and Corso, Anthony and Kochenderfer, Mykel J},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={33},
  number={1},
  pages={198--202},
  year={2023}
}

@article{sardar2019impact,
  title={Impact of artificial intelligence on interventional cardiology: from decision-making aid to advanced interventional procedure assistance},
  author={Sardar, Partha and Abbott, J Dawn and Kundu, Amartya and Aronow, Herbert D and Granada, Juan F and Giri, Jay},
  journal={Cardiovascular interventions},
  volume={12},
  number={14},
  pages={1293--1303},
  year={2019},
  publisher={American College of Cardiology Foundation Washington DC}
}

@article{holzinger2018challenges,
  title={Challenges and potential in space domain awareness},
  author={Holzinger, Marcus J and Jah, Moribah K},
  journal={Journal of Guidance, Control, and Dynamics},
  volume={41},
  number={1},
  pages={15--18},
  year={2018},
  publisher={American Institute of Aeronautics and Astronautics}
}

@article{smith1990task,
  title={The Task of the Referee},
  author={Smith, Alan Jay},
  journal={Computer},
  volume={23},
  number={4},
  pages={65--71},
  year={1990},
  publisher={IEEE}
}

@article{burch2014solving,
	title = {Solving Imperfect Information Games Using Decomposition},
	volume = {28},
	rights = {Copyright (c)},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/8810},
	doi = {10.1609/aaai.v28i1.8810},
	number = {1},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Burch, Neil and Johanson, Michael and Bowling, Michael},
	urldate = {2023-11-12},
	date = {2014-06-21},
	langid = {english},
	note = {Number: 1},
}


@inproceedings{chong1983distributed,
	title = {Distributed Estimation in Networks},
	url = {https://ieeexplore.ieee.org/document/4788119},
	doi = {10.23919/ACC.1983.4788119},
	eventtitle = {1983 American Control Conference},
	pages = {294--300},
	booktitle = {1983 American Control Conference},
	author = {Chong, C. Y. and Tse, E. and Mori, S.},
	urldate = {2023-12-06},
	date = {1983-06}
}

@article{grime1994data,
	title = {Data fusion in decentralized sensor networks},
	volume = {2},
	issn = {0967-0661},
	url = {https://www.sciencedirect.com/science/article/pii/0967066194903492},
	doi = {10.1016/0967-0661(94)90349-2},
	pages = {849--863},
	number = {5},
	journaltitle = {Control Engineering Practice},
	shortjournal = {Control Engineering Practice},
	author = {Grime, S. and Durrant-Whyte, H. F.},
	urldate = {2023-12-06},
	date = {1994-10-01},
	keywords = {Data Fusion, Decentralized Systems}
}

@inproceedings{julier1997non-divergent,
	title = {A non-divergent estimation algorithm in the presence of unknown correlations},
	volume = {4},
	url = {https://ieeexplore.ieee.org/document/609105},
	doi = {10.1109/ACC.1997.609105},
	eventtitle = {Proceedings of the 1997 American Control Conference (Cat. No.97CH36041)},
	pages = {2369--2373 vol.4},
	booktitle = {Proceedings of the 1997 American Control Conference (Cat. No.97CH36041)},
	author = {Julier, S.J. and Uhlmann, J.K.},
	urldate = {2023-12-06},
	date = {1997-06},
	note = {{ISSN}: 0743-1619}
}

@article{dagan2023exact,
	title = {Exact and Approximate Heterogeneous Bayesian Decentralized Data Fusion},
	volume = {39},
	issn = {1941-0468},
	url = {https://ieeexplore.ieee.org/document/9985432},
	doi = {10.1109/TRO.2022.3226115},
	pages = {1136--1150},
	number = {2},
	journaltitle = {{IEEE} Transactions on Robotics},
	author = {Dagan, Ofer and Ahmed, Nisar R.},
	urldate = {2023-12-06},
	date = {2023-04},
	note = {Conference Name: {IEEE} Transactions on Robotics}
}

@article{schmid2019variance,
	title = {Variance Reduction in Monte Carlo Counterfactual Regret Minimization ({VR}-{MCCFR}) for Extensive Form Games Using Baselines},
	volume = {33},
	rights = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4048},
	doi = {10.1609/aaai.v33i01.33012157},
	pages = {2157--2164},
	number = {1},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Schmid, Martin and Burch, Neil and Lanctot, Marc and Moravcik, Matej and Kadlec, Rudolf and Bowling, Michael},
	urldate = {2023-12-08},
	date = {2019-07-17},
	langid = {english}
}

@article{lauri2022partially,
  title={Partially Observable {M}arkov Decision Processes in Robotics: A Survey},
  author={Lauri, Mikko and Hsu, David and Pajarinen, Joni},
  journal={{IEEE} Transactions on Robotics},
  volume={39},
  number={1},
  pages={21--40},
  year={2022},
  publisher={IEEE}
}


@article{kurniawati2022partially,
  title={Partially Observable {M}arkov Decision Processes and Robotics},
  author={Kurniawati, Hanna},
  journal={Annual Review of Control, Robotics, and Autonomous Systems},
  volume={5},
  pages={253--277},
  year={2022},
  publisher={Annual Reviews}
}
